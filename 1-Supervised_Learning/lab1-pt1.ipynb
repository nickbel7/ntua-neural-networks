{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1nskBgmzmD-"
      },
      "source": [
        "### Στοιχεία ομάδας (Ομάδα 1):\n",
        "\n",
        "```\n",
        "Neural Networks - Lab 1\n",
        "Creators : \n",
        "Αναστάσης Αγγλογάλλος\n",
        "Παναγιώτης Κοκκινάκης\n",
        "Νικόλας Μπέλλος\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgBhMPlXWn4N"
      },
      "source": [
        "# Μέρος 1. UCI dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovIu0BWetkI_"
      },
      "source": [
        "# Εισαγωγή και Επισκόπηση:\n",
        "\n",
        "Το Dataset που χρησιμοποιήσαμε είναι το HCC Survival Data Set. Πρόκειται για δεδομένα ασθενών που πάσχουν από Υπατοκυτταρικό Καρκίνωμα τα οποία συλλέχθησαν στο University Hospital στην Πορτογαλία. Το Dataset περιλαμβάνει 49 διαφορετικά χαρακτηριστικά από 165 ασθενείς, ενώ στα δεδομένα δεν περιέχονται επικεφαλίδες ή αρίθμηση γραμμών. Από τα 49 χαρακτηριστικά τα 26 είναι ποιοτικά και τα 23 ποσοτικά. Τα απουσιάζοντα δεδομένα αποτελούν το 10.22% του συνολικού Dataset, ενώ μόνο 4/165 ασθενείς έχουν πληροφορίες σε όλα τα πεδία. Κύριος στόχος είναι η εξάλειψη συμπερασμάτων για το αν ο ασθενής επιβίωσε έναν χρόνο μετά τη διάγνωση, χαρακτηριστικό που κωδικοποιείται με 1 (έζησε) ή 0 (απεβίωσε) ενώ οι ετικέτες κλάσης βρίσκονται στην τελευταία στήλη. Οι δύο κλάσεις (έζησε-απεβίωσε) εμφανίζονται σε ποσοστά 38.18% και 61.82% αντίστοιχα. Επομένως υπάρχει class imbalance αφού η μία κλάση είναι τουλάχιστον 1.5 φορές πιο συχνά εμφανιζόμενη από την άλλη. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mujLPRdD8VfA"
      },
      "source": [
        "# 1. Προετοιμασία\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8BufFmVYZQh",
        "outputId": "a5d2b9cd-c4c0-4b06-f601-2680a9675310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 13.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/112.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.1/147.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=e551bcfc1c90f2c014389b850f5a964992eb58b533f63c90ea6dab85fa268d88\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/86/43/c32981b55b0d0a78b9762fd4fa7d6de0da0a46fd035cedfccb\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorlog, cmaes, autopage, stevedore, Mako, cmd2, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (3.1.0)\n",
            "  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "Successfully installed imbalanced-learn-0.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (59.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (4.13.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray) (3.10.0)\n",
            "Installing collected packages: distlib, platformdirs, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 platformdirs-2.5.4 ray-2.1.0 virtualenv-20.16.7\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (20.16.7)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.50.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (22.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.6)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.8.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (2.5.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (4.13.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray[tune]) (3.10.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tune-sklearn\n",
            "  Downloading tune_sklearn-0.4.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ray[tune]>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (2.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.0.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (3.19.6)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (20.16.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (1.50.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (4.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (1.0.4)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (3.8.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (4.3.3)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (1.3.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (22.1.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (2.5.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (0.8.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]>=2.0.0->tune-sklearn) (1.3.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune-sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune-sklearn) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray[tune]>=2.0.0->tune-sklearn) (1.15.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]>=2.0.0->tune-sklearn) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]>=2.0.0->tune-sklearn) (0.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]>=2.0.0->tune-sklearn) (4.13.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]>=2.0.0->tune-sklearn) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]>=2.0.0->tune-sklearn) (5.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]>=2.0.0->tune-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]>=2.0.0->tune-sklearn) (2022.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]>=2.0.0->tune-sklearn) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]>=2.0.0->tune-sklearn) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]>=2.0.0->tune-sklearn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]>=2.0.0->tune-sklearn) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray[tune]>=2.0.0->tune-sklearn) (3.10.0)\n",
            "Installing collected packages: tune-sklearn\n",
            "Successfully installed tune-sklearn-0.4.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip \n",
        "!pip install --upgrade scikit-learn \n",
        "!pip install --upgrade numpy \n",
        "!pip install --upgrade scipy \n",
        "!pip install --upgrade pandas\n",
        "!pip install optuna \n",
        "!pip install -U imbalanced-learn\n",
        "!pip install -U ray \n",
        "!pip install -U ray[tune]\n",
        "!pip install -U tune-sklearn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "VzO_8eqUZzr4",
        "outputId": "32f25512-f064-49e6-be3b-31cadd08bef6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c9febe4-a13a-4609-93b4-af8209cdf776\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c9febe4-a13a-4609-93b4-af8209cdf776\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving hcc-data.txt to hcc-data.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qK5SkMRVsIW"
      },
      "source": [
        "## Split Data Set (train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV-m_m4EYflB",
        "outputId": "80c99341-fdba-4209-c33c-c4a01ec9fbe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     0  1   2  3  4  5  6   7  8  9   ...   40   41    42 43    44    45  46  47  48 49\n",
            "0     1  0   1  0  0  0  0   1  0  1  ...  150  7.1   0.7  1   3.5   0.5   ?   ?   ?  1\n",
            "1     0  ?   0  0  0  0  1   1  ?  ?  ...    ?    ?     ?  1   1.8     ?   ?   ?   ?  1\n",
            "2     1  0   1  1  0  1  0   1  0  1  ...  109    7   2.1  5    13   0.1  28   6  16  1\n",
            "3     1  1   1  0  0  0  0   1  0  1  ...  174  8.1  1.11  2  15.7   0.2   ?   ?   ?  0\n",
            "4     1  1   1  1  0  1  0   1  0  1  ...  109  6.9   1.8  1     9     ?  59  15  22  1\n",
            "..   .. ..  .. .. .. .. ..  .. .. ..  ...  ...  ...   ... ..   ...   ...  ..  ..  .. ..\n",
            "160   0  0   1  ?  ?  ?  1   1  0  1  ...  109  7.6   0.7  5     3     ?   ?   ?   ?  1\n",
            "161   0  1   0  ?  ?  ?  ?   1  0  0  ...  280  6.7   0.7  1   2.2   2.3   ?   ?   ?  0\n",
            "162   1  0   1  0  0  0  0   1  0  1  ...  181  7.5  1.46  5  18.6     ?   ?   ?   ?  1\n",
            "163   1  0   1  1  0  1  1   1  1  1  ...  170  8.4  0.74  5    18     ?   ?   ?   ?  0\n",
            "164   1  1   1  0  0  0  1   1  0  1  ...  462  6.6  3.95  5   8.5  19.8   ?   ?   ?  0\n",
            "\n",
            "[165 rows x 50 columns]\n",
            "--------------------------------------------\n",
            "Entire Data Set (size) : (165, 50)\n",
            "Train Set (size) : (115, 50)\n",
            "Test Set (size) : (50, 50)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import RandomState\n",
        "\n",
        "# Print arrray inline\n",
        "pd.set_option('expand_frame_repr', False)\n",
        "\n",
        "all_data = pd.read_csv(\"/content/hcc-data.txt\", header=None)\n",
        "print(all_data)\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "# Split dataset into TRAIN SET and TEST SET\n",
        "\n",
        "#rng = RandomState()\n",
        "#train_set = all_data.sample(frac=0.7, random_state=rng)\n",
        "train_set = all_data.sample(frac=0.7, random_state=42)\n",
        "test_set = all_data.loc[~all_data.index.isin(train_set.index)]\n",
        "\n",
        "print(\"Entire Data Set (size) : \" + str(all_data.shape))\n",
        "print(\"Train Set (size) : \" + str(train_set.shape))\n",
        "print(\"Test Set (size) : \" + str(test_set.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cONBmEiyWGfn"
      },
      "source": [
        "## Handle missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtAwgoSsWc7G"
      },
      "source": [
        "**Αιτιολόγηση για διαχείρηση των missing values**\n",
        "\n",
        "Χρησιμοποιούμε δύο διαφορετικές μεθόδους για να διαχειριστούμε με τον ίδιο τρόπο τις τιμές που λείπουν.\n",
        "1. Για το train Θα πρέπει για τις ποιοτικές τιμές να υπολογίσουμε την πιο συχνή ενώ για τις ποσοτικές να υπολογίσουμε τον μέσο όρο τους\n",
        "2. Θα εφαρμόσουμε τις τιμές αυτές (ποιοτικές, ποσοτικές) σε όλα missing values τόσο του train set όσο και του test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4xeWzzPvonJ",
        "outputId": "71491ba6-d337-4570-e159-fb5353aee0a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5244: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# replace ? with NaN\n",
        "train_set.replace('?',np.NaN,inplace=True)\n",
        "test_set.replace('?',np.NaN,inplace=True)\n",
        "\n",
        "# mark which columns contain qualitative data\n",
        "quant_columns = np.concatenate((np.arange(0, 23), np.arange(26,29))) #ex. {0, 1, 2}\n",
        "\n",
        "# replace NaN values with the mean of the each column\n",
        "imputer_mean = SimpleImputer(missing_values=np.NaN,strategy='mean')\n",
        "imputer_most_frequent = SimpleImputer(missing_values=np.NaN,strategy='most_frequent')\n",
        "imputer_median = SimpleImputer(missing_values=np.NaN,strategy='median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnmD7CCCWWZi",
        "outputId": "04ac5f8b-c541-4940-c2ec-51a9337e563d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN SET (OLD - NEW)\n",
            "     0  1   2    3    4    5    6   7  8    9   ...   40   41    42   43    44   45   46   47   48 49\n",
            "135   0  1   0    0    0    0    0   1  0    0  ...  123  6.8  0.82    5   8.3  NaN  NaN  NaN  NaN  1\n",
            "115   1  1   1    0  NaN  NaN    0   1  0    1  ...  629  8.4  0.71    5   9.1  0.3  NaN  NaN  NaN  1\n",
            "131   0  0   1  NaN  NaN  NaN    0   1  0  NaN  ...  147  6.5     1    5   2.6  3.8  NaN  NaN  NaN  1\n",
            "55    0  1   0  NaN  NaN  NaN    1   0  0    0  ...  923  5.4  1.31    3  15.4  NaN  NaN  NaN  NaN  0\n",
            "95    1  0   0    0    0    0    0   0  0    0  ...  124  6.8   1.6    1   5.5  NaN   15    7  810  0\n",
            "..   .. ..  ..  ...  ...  ...  ...  .. ..  ...  ...  ...  ...   ...  ...   ...  ...  ...  ...  ... ..\n",
            "46    0  1   0    0    0    0    0   0  0    0  ...  NaN  NaN   NaN  NaN   NaN  NaN  NaN  NaN  NaN  1\n",
            "7     1  1   1    0  NaN    0    0   1  0    1  ...  300  7.1  0.52    2     9  1.3   42   25  706  0\n",
            "43    1  0   1  NaN  NaN  NaN  NaN   1  0  NaN  ...   56  7.3   0.7    1     2  0.2  NaN  NaN  NaN  1\n",
            "70    0  1   0    0    0    1    0   1  1    0  ...   94  4.9   0.2    2   5.4  0.8   50   16   20  1\n",
            "125   1  1   1    0    0    0    0   1  0  NaN  ...  217  6.3   0.7    1    20  0.5   52   17  832  0\n",
            "\n",
            "[115 rows x 50 columns]\n",
            "      0    1    2    3    4    5    6    7    8    9   ...      40    41    42    43     44    45     46     47      48   49\n",
            "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  123.00  6.80  0.82  5.00   8.30  1.68  85.63  35.38  422.73  1.0\n",
            "1    1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  629.00  8.40  0.71  5.00   9.10  0.30  85.63  35.38  422.73  1.0\n",
            "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  147.00  6.50  1.00  5.00   2.60  3.80  85.63  35.38  422.73  1.0\n",
            "3    0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  923.00  5.40  1.31  3.00  15.40  1.68  85.63  35.38  422.73  0.0\n",
            "4    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  124.00  6.80  1.60  1.00   5.50  1.68  15.00   7.00  810.00  0.0\n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...   ...   ...   ...    ...   ...    ...    ...     ...  ...\n",
            "110  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  222.21  9.83  1.11  2.75   6.43  1.68  85.63  35.38  422.73  1.0\n",
            "111  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  300.00  7.10  0.52  2.00   9.00  1.30  42.00  25.00  706.00  0.0\n",
            "112  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   56.00  7.30  0.70  1.00   2.00  0.20  85.63  35.38  422.73  1.0\n",
            "113  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   94.00  4.90  0.20  2.00   5.40  0.80  50.00  16.00   20.00  1.0\n",
            "114  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  217.00  6.30  0.70  1.00  20.00  0.50  52.00  17.00  832.00  0.0\n",
            "\n",
            "[115 rows x 50 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply imputer to train set\n",
        "train_set_new = pd.DataFrame(imputer_mean.fit_transform(train_set))\n",
        "train_set_new = np.round(train_set_new, decimals=2) #round them up\n",
        "\n",
        "# round qualitive numbers\n",
        "train_set_rows = np.shape(train_set)[0]\n",
        "train_set_columns = np.shape(train_set)[1]\n",
        "for i in range (train_set_rows):\n",
        "  for j in range (train_set_columns):\n",
        "    if (j in quant_columns):\n",
        "      train_set_new[j][i] = np.round(train_set_new[j][i], decimals=0)\n",
        "\n",
        "# PRINT TRAIN SET\n",
        "print(\"TRAIN SET (OLD - NEW)\")\n",
        "print(train_set)\n",
        "print(train_set_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PxhakTAsyGP",
        "outputId": "4cc58b4c-1020-4204-c09d-eb910f336323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST SET (OLD - NEW)\n",
            "     0    1   2    3    4    5    6   7    8    9   ...    40   41    42   43    44    45   46    47    48 49\n",
            "0     1    0   1    0    0    0    0   1    0    1  ...   150  7.1   0.7    1   3.5   0.5  NaN   NaN   NaN  1\n",
            "3     1    1   1    0    0    0    0   1    0    1  ...   174  8.1  1.11    2  15.7   0.2  NaN   NaN   NaN  0\n",
            "8     1    1   1    0    0    0    0   1    0    1  ...    63  6.1  0.59    1   6.4   1.2   85    73   982  1\n",
            "11    1    0   1    0    0    0    1   1    1    0  ...   154  NaN   7.6    5   1.9   0.3  144    41   277  1\n",
            "14    1    0   1    0    0    0    0   1    0  NaN  ...   163  7.3  1.07    4   4.5   4.5  197    84   302  1\n",
            "15    0    0   1    0    0    0    0   1    0    0  ...   176    5   0.8    2   2.6   1.3   25    13    60  1\n",
            "19    1    1   1    0    0    0    0   1  NaN  NaN  ...   147  6.3   0.9    5   2.3   1.6   67    34   774  0\n",
            "21    1    0   1    0    0    1    1   1    0    1  ...    97  6.3  0.75    1   6.8   0.2   87    26    84  1\n",
            "22    1    1   1    0    0    1    0   1  NaN    0  ...   562   69  1.14    5   3.8   0.5  112    73  1001  0\n",
            "23    1    1   1    0    0    0    0   1    1    1  ...   396    7  0.53    5    15   1.6  NaN   NaN   NaN  0\n",
            "24    1    1   1    0  NaN    1    0   0    0    1  ...   311  5.6  0.95    1    10   0.7  NaN   NaN   NaN  0\n",
            "25    1    0   1    0  NaN    0    0   1    0    0  ...   233  8.4  0.79    5   NaN   0.7   93    31    79  1\n",
            "32    1    1   1  NaN  NaN  NaN    0   1  NaN  NaN  ...   135  8.2   0.9    2   NaN   NaN  NaN   NaN   NaN  1\n",
            "37    1    1   1    0    0    0    0   1  NaN    1  ...   209  6.7   1.4    5   4.9   0.2   57    25   134  0\n",
            "45    1    0   1    0    0    0    0   1    0    0  ...    68  8.3  0.72    1   2.3   NaN  NaN   NaN   NaN  1\n",
            "46    0    1   0    0    0    0    0   0    0    0  ...   NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN  1\n",
            "51    0    0   1  NaN  NaN  NaN    1   1  NaN    0  ...   350  7.3   1.7    5   NaN   0.8   84    37   497  0\n",
            "53    1  NaN   1    0    0    0    0   1    0    0  ...   130  NaN  0.76    2     2   0.3  184  2.26    59  1\n",
            "54    1    1   1    0    0    0    1   1  NaN    1  ...   397  6.7  0.82    1   2.1   5.5   56    27   742  0\n",
            "57    1  NaN   1    0    0    0    0   1    0    1  ...   120    7  0.58    1   4.7  0.85   32    10    18  1\n",
            "62    0    0   1    0    0    0    0   1    0    1  ...   178  6.1  0.62    1   4.6   2.2  NaN   NaN   NaN  1\n",
            "65    0    1   0    0    0    0    0   1    0    0  ...   104  5.4   0.6    5   7.8   0.2   46    18   NaN  0\n",
            "69    0    1   1    0    0    1    0   1  NaN    0  ...   260  5.9   NaN    5     3   1.3   15    17   639  0\n",
            "70    0    1   0    0    0    1    0   1    1    0  ...    94  4.9   0.2    2   5.4   0.8   50    16    20  1\n",
            "71    1    1   1    0    0    0    0   1    0    1  ...   417  6.5  0.64    5    15   1.1  NaN   NaN   NaN  1\n",
            "72    1    1   1    0    0    0    0   1  NaN    1  ...  1.28  6.7   1.5    5     4   0.8   26    15   227  1\n",
            "73    1    1   1    0    0    0    0   1    0    0  ...   684  7.1  0.81    5   NaN   NaN  NaN   NaN   NaN  0\n",
            "74    1    1   1    0  NaN    0    0   1    0    1  ...   101  7.4   1.1    5   7.5   0.3   61   NaN   255  1\n",
            "76    1    1   1    0    0    0    0   1    0  NaN  ...   165  7.7  0.83    1   4.5   1.2   72  29.5   355  0\n",
            "78    1    1   1    0    0    0    0   1    0  NaN  ...    88  5.6   NaN    5   4.7   0.5   19     8   141  1\n",
            "89    1    0   1    0    0    1    0   1    0    1  ...   474  3.9  2.69    1     2     1  NaN   NaN   NaN  1\n",
            "93    1    1   1    0    0    0    0   1    0    1  ...   335  7.1  0.68    5   NaN   0.6  NaN   NaN   NaN  0\n",
            "95    1    0   0    0    0    0    0   0    0    0  ...   124  6.8   1.6    1   5.5   NaN   15     7   810  0\n",
            "97    1    0   1    0    0    0    0   1    0  NaN  ...   137  6.8  0.67    4   4.7   1.1  NaN   NaN   NaN  1\n",
            "100   1    1   1  NaN  NaN  NaN    0   1    0    0  ...   297  5.7  2.19    5   NaN   1.5   55    33   256  1\n",
            "101   1    1   0    0    0    0    1   1    0  NaN  ...   262  6.9   1.2    5     4  19.5  121    27   749  0\n",
            "110   1    1   1    1    0    1    0   1  NaN    1  ...   166  7.2  0.48    5  12.6   1.8  161    96   297  1\n",
            "115   1    1   1    0  NaN  NaN    0   1    0    1  ...   629  8.4  0.71    5   9.1   0.3  NaN   NaN   NaN  1\n",
            "117   1    1   1    1    1    1    0   1    0  NaN  ...   146    8  3.23    1   NaN   9.7  106    67  2165  0\n",
            "118   1    0   1    0    0    0    0   1    0    0  ...    79  7.7  1.02    1     3   NaN  NaN   NaN   NaN  1\n",
            "120   1    1   0    1    0  NaN    0   1    1    0  ...   980  7.5  0.78    5     9   2.8  NaN   NaN   NaN  1\n",
            "123   1    0   0    0    0    0    0   0    0    0  ...   151  6.4   1.5    1   8.3   NaN   88    27    90  1\n",
            "124   1    1   1    0    0    1    1   1  NaN    1  ...   466  7.3   0.7    1   8.3   NaN  NaN   NaN   579  0\n",
            "127   1    0   1    0    0    0  NaN   1    0    0  ...   182  6.2  0.77    2   4.3     1   93    47   307  1\n",
            "132   0    0   0    0    0    0    1   1  NaN    0  ...   106  7.1   6.1    2     9   0.7  NaN   NaN   NaN  0\n",
            "145   1    1   1    0    0    0    0   1    0  NaN  ...   141  NaN   1.1    1    15  0.33  NaN   NaN   NaN  1\n",
            "152   1    1   1    0    0    0    1   1    0    1  ...    44    7  0.96    5   3.5   NaN  NaN   NaN   NaN  1\n",
            "153   1    1   1  NaN  NaN  NaN    0   1    0    0  ...   338    7  1.13    1    15   1.3  NaN   NaN   NaN  0\n",
            "155   1    1   1    0    0    0    0   1  NaN    1  ...   139  7.6   0.9    3     9   2.9  111    94  1600  0\n",
            "161   0    1   0  NaN  NaN  NaN  NaN   1    0    0  ...   280  6.7   0.7    1   2.2   2.3  NaN   NaN   NaN  0\n",
            "\n",
            "[50 rows x 50 columns]\n",
            "     0    1    2    3    4    5    6    7    8    9   ...      40     41    42    43     44     45      46     47       48   49\n",
            "0   1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  150.00   7.10  0.70  1.00   3.50   0.50   87.92  37.41   417.82  1.0\n",
            "1   1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  174.00   8.10  1.11  2.00  15.70   0.20   87.92  37.41   417.82  0.0\n",
            "2   1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...   63.00   6.10  0.59  1.00   6.40   1.20   85.00  73.00   982.00  1.0\n",
            "3   1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  ...  154.00   9.31  7.60  5.00   1.90   0.30  144.00  41.00   277.00  1.0\n",
            "4   1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  163.00   7.30  1.07  4.00   4.50   4.50  197.00  84.00   302.00  1.0\n",
            "5   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  176.00   5.00  0.80  2.00   2.60   1.30   25.00  13.00    60.00  1.0\n",
            "6   1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  147.00   6.30  0.90  5.00   2.30   1.60   67.00  34.00   774.00  0.0\n",
            "7   1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  1.0  ...   97.00   6.30  0.75  1.00   6.80   0.20   87.00  26.00    84.00  1.0\n",
            "8   1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  562.00  69.00  1.14  5.00   3.80   0.50  112.00  73.00  1001.00  0.0\n",
            "9   1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  ...  396.00   7.00  0.53  5.00  15.00   1.60   87.92  37.41   417.82  0.0\n",
            "10  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  311.00   5.60  0.95  1.00  10.00   0.70   87.92  37.41   417.82  0.0\n",
            "11  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  233.00   8.40  0.79  5.00   7.03   0.70   93.00  31.00    79.00  1.0\n",
            "12  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  135.00   8.20  0.90  2.00   7.03   1.97   87.92  37.41   417.82  1.0\n",
            "13  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  209.00   6.70  1.40  5.00   4.90   0.20   57.00  25.00   134.00  0.0\n",
            "14  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   68.00   8.30  0.72  1.00   2.30   1.97   87.92  37.41   417.82  1.0\n",
            "15  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  201.55   9.31  1.07  2.61   7.03   1.97   87.92  37.41   417.82  1.0\n",
            "16  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  ...  350.00   7.30  1.70  5.00   7.03   0.80   84.00  37.00   497.00  0.0\n",
            "17  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  130.00   9.31  0.76  2.00   2.00   0.30  184.00   2.26    59.00  1.0\n",
            "18  1.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  ...  397.00   6.70  0.82  1.00   2.10   5.50   56.00  27.00   742.00  0.0\n",
            "19  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  120.00   7.00  0.58  1.00   4.70   0.85   32.00  10.00    18.00  1.0\n",
            "20  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  178.00   6.10  0.62  1.00   4.60   2.20   87.92  37.41   417.82  1.0\n",
            "21  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  104.00   5.40  0.60  5.00   7.80   0.20   46.00  18.00   417.82  0.0\n",
            "22  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  260.00   5.90  1.07  5.00   3.00   1.30   15.00  17.00   639.00  0.0\n",
            "23  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  ...   94.00   4.90  0.20  2.00   5.40   0.80   50.00  16.00    20.00  1.0\n",
            "24  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  417.00   6.50  0.64  5.00  15.00   1.10   87.92  37.41   417.82  1.0\n",
            "25  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...    1.28   6.70  1.50  5.00   4.00   0.80   26.00  15.00   227.00  1.0\n",
            "26  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  684.00   7.10  0.81  5.00   7.03   1.97   87.92  37.41   417.82  0.0\n",
            "27  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  101.00   7.40  1.10  5.00   7.50   0.30   61.00  37.41   255.00  1.0\n",
            "28  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  165.00   7.70  0.83  1.00   4.50   1.20   72.00  29.50   355.00  0.0\n",
            "29  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...   88.00   5.60  1.07  5.00   4.70   0.50   19.00   8.00   141.00  1.0\n",
            "30  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  ...  474.00   3.90  2.69  1.00   2.00   1.00   87.92  37.41   417.82  1.0\n",
            "31  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  335.00   7.10  0.68  5.00   7.03   0.60   87.92  37.41   417.82  0.0\n",
            "32  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  124.00   6.80  1.60  1.00   5.50   1.97   15.00   7.00   810.00  0.0\n",
            "33  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  137.00   6.80  0.67  4.00   4.70   1.10   87.92  37.41   417.82  1.0\n",
            "34  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  297.00   5.70  2.19  5.00   7.03   1.50   55.00  33.00   256.00  1.0\n",
            "35  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  ...  262.00   6.90  1.20  5.00   4.00  19.50  121.00  27.00   749.00  0.0\n",
            "36  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  ...  166.00   7.20  0.48  5.00  12.60   1.80  161.00  96.00   297.00  1.0\n",
            "37  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  629.00   8.40  0.71  5.00   9.10   0.30   87.92  37.41   417.82  1.0\n",
            "38  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  ...  146.00   8.00  3.23  1.00   7.03   9.70  106.00  67.00  2165.00  0.0\n",
            "39  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   79.00   7.70  1.02  1.00   3.00   1.97   87.92  37.41   417.82  1.0\n",
            "40  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  980.00   7.50  0.78  5.00   9.00   2.80   87.92  37.41   417.82  1.0\n",
            "41  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  151.00   6.40  1.50  1.00   8.30   1.97   88.00  27.00    90.00  1.0\n",
            "42  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  1.0  ...  466.00   7.30  0.70  1.00   8.30   1.97   87.92  37.41   579.00  0.0\n",
            "43  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  182.00   6.20  0.77  2.00   4.30   1.00   93.00  47.00   307.00  1.0\n",
            "44  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  ...  106.00   7.10  6.10  2.00   9.00   0.70   87.92  37.41   417.82  0.0\n",
            "45  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  141.00   9.31  1.10  1.00  15.00   0.33   87.92  37.41   417.82  1.0\n",
            "46  1.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  ...   44.00   7.00  0.96  5.00   3.50   1.97   87.92  37.41   417.82  1.0\n",
            "47  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  338.00   7.00  1.13  1.00  15.00   1.30   87.92  37.41   417.82  0.0\n",
            "48  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  139.00   7.60  0.90  3.00   9.00   2.90  111.00  94.00  1600.00  0.0\n",
            "49  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  280.00   6.70  0.70  1.00   2.20   2.30   87.92  37.41   417.82  0.0\n",
            "\n",
            "[50 rows x 50 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply imputer to test set\n",
        "test_set_new = pd.DataFrame(imputer_mean.transform(test_set.values))\n",
        "test_set_new = np.round(test_set_new, decimals=2) #round them up\n",
        "\n",
        "# round qualitive numbers\n",
        "test_set_rows = np.shape(test_set)[0]\n",
        "test_set_columns = np.shape(test_set)[1]\n",
        "for i in range (test_set_rows):\n",
        "  for j in range (test_set_columns):\n",
        "    if (j in quant_columns):\n",
        "      test_set_new[j][i] = np.round(test_set_new[j][i], decimals=0)\n",
        "\n",
        "# PRINT TEST SET\n",
        "print(\"TEST SET (OLD - NEW)\")\n",
        "print(test_set)\n",
        "print(test_set_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMHhzDHk4jc"
      },
      "source": [
        "# Ταξινόμηση\n",
        "\n",
        "Θα χρησιμοποιήσουμε τους εξής ταξινομητές για να αξιολογήσουμε την αποτελεσματικότητα τους στο συγκεκριμένο Dataset. \n",
        "\n",
        "1.  dummy\n",
        "2.  Gaussian Naive Bayes (GNB),\n",
        "3.  KNeirestNeighbors (kNN), και\n",
        "4.  Logistic Regression (LR)\n",
        "\n",
        "Αρχικά θα χρησιμοποιήσουμε τους ταξινομητές χωρίς κάποια βελτιστοποίηση με τις default ρυθμίσεις τους, και στη συνέχεια θα εφαρμόσουμε διάφορες τεχνικές optimization για να βελτιώσουμε την επίδοση τους.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "JOhrOvlFORsH"
      },
      "outputs": [],
      "source": [
        "# Import all neccessairy libraries\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4Db0Q_4M9VF"
      },
      "source": [
        "## Out-of-the-box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "jm3BTGSYWTvo"
      },
      "outputs": [],
      "source": [
        "# Splitting datasets into data and targets\n",
        "\n",
        "# Train Set\n",
        "train_data = train_set_new.iloc[:, :49]\n",
        "train_targets = train_set_new.iloc[:, -1]\n",
        "\n",
        "# Test Set\n",
        "test_data = test_set_new.iloc[:, :49]\n",
        "test_targets = test_set_new.iloc[:, -1]\n",
        "# Also works for test_set_new.iloc[:, 49:]\n",
        "\n",
        "# test_targets = test_targets.astype(int)\n",
        "# train_targets = train_targets.astype(int)\n",
        "\n",
        "# print(test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "1a3n7ccY7ELt"
      },
      "outputs": [],
      "source": [
        "# Transform the datasets to work better with the following methods\n",
        "x_train = train_data; y_train = train_targets.values.ravel()\n",
        "x_test = test_data; y_test = test_targets.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d0VcJ9QliMj",
        "outputId": "eb2996fd-567a-4426-a9a0-beb5b53a93f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(115, 49) (115,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(x_train), np.shape(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXHrqoI6WYK1"
      },
      "source": [
        "### Dummy Classifier\n",
        "\n",
        "Χρησιμοποιούμε τον Dummy Classifier με 4 διαφορετικές στρατηγικές, σαν baseline για να συγκρίνουμε με τις υπόλοιπες μεθόδους."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "t408StkMRjnR"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "#1 Output based on uniform distribution of 0 and 1 (50/50)\n",
        "dummy_clf_uniform = DummyClassifier(strategy=\"uniform\", random_state = 1)\n",
        "\n",
        "#2 Chooses most frequent class\n",
        "dummy_clf_mf = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "#3 Always outputs one specific class (0 or 1)\n",
        "dummy_clf_constant_0 = DummyClassifier(strategy=\"constant\", constant=0)\n",
        "dummy_clf_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "\n",
        "#4 Output based on distribution of classes in training set (ex. 30% -> 1, 70% -> 0)\n",
        "dummy_clf_str = DummyClassifier(strategy=\"stratified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoVYXjC7ll6u",
        "outputId": "ad8bf215-affa-4284-c1a2-76931e326150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy for the Train Set \n",
            "\n",
            "Dummy Classifiers Scores\n",
            "most frequent\t\t:  0.6173913043478261\n",
            "constant 1\t\t:  0.6173913043478261\n",
            "stratified\t\t:  0.6086956521739131\n",
            "uniform \t\t:  0.5478260869565217\n",
            "constant 0\t\t:  0.3826086956521739\n"
          ]
        }
      ],
      "source": [
        "# Measuring the accuracy for the train data and sorting the classifiers\n",
        "train_accuracy = {}\n",
        "\n",
        "#1\n",
        "dummy_clf_uniform.fit(train_data, train_targets)\n",
        "train_accuracy['uniform '] = dummy_clf_uniform.score(train_data, train_targets)\n",
        "#2\n",
        "dummy_clf_mf.fit(train_data, train_targets)\n",
        "train_accuracy['most frequent'] = dummy_clf_mf.score(train_data, train_targets)\n",
        "#3\n",
        "dummy_clf_constant_0.fit(train_data, train_targets)\n",
        "train_accuracy['constant 0'] = dummy_clf_constant_0.score(train_data, train_targets)\n",
        "dummy_clf_constant_1.fit(train_data, train_targets)\n",
        "train_accuracy['constant 1'] = dummy_clf_constant_1.score(train_data, train_targets)\n",
        "#4\n",
        "dummy_clf_str.fit(train_data, train_targets)\n",
        "train_accuracy['stratified'] = dummy_clf_str.score(train_data, train_targets)\n",
        "\n",
        "# Sort the accuracies\n",
        "print(\"Classification Accuracy for the Train Set \\n\")\n",
        "sorted_accuracy = [(k, train_accuracy[k]) for k in sorted(train_accuracy, key=train_accuracy.get, reverse=True)]\n",
        "print(\"Dummy Classifiers Scores\")\n",
        "for clf, score in sorted_accuracy:\n",
        "  print(str(clf) + \"\\t\\t: \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6i_LN7lWsgx",
        "outputId": "d7eefa36-5ba9-4ab1-80f7-454d944f47aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy for the Test Set \n",
            "\n",
            "Dummy Classifiers Scores\n",
            "most frequent\t\t:  0.58\n",
            "constant 1\t\t:  0.58\n",
            "stratified\t\t:  0.52\n",
            "uniform \t\t:  0.48\n",
            "constant 0\t\t:  0.42\n"
          ]
        }
      ],
      "source": [
        "# Measuring the accuracy for the test data and sorting the classifiers\n",
        "test_accuracy = {}\n",
        "\n",
        "#1\n",
        "dummy_clf_uniform.fit(test_data, test_targets)\n",
        "test_accuracy['uniform '] = dummy_clf_uniform.score(test_data, test_targets)\n",
        "#2\n",
        "dummy_clf_mf.fit(test_data, test_targets)\n",
        "test_accuracy['most frequent'] = dummy_clf_mf.score(test_data, test_targets)\n",
        "#3\n",
        "dummy_clf_constant_0.fit(test_data, test_targets)\n",
        "test_accuracy['constant 0'] = dummy_clf_constant_0.score(test_data, test_targets)\n",
        "dummy_clf_constant_1.fit(test_data, test_targets)\n",
        "test_accuracy['constant 1'] = dummy_clf_constant_1.score(test_data, test_targets)\n",
        "#4\n",
        "dummy_clf_str.fit(test_data, test_targets)\n",
        "test_accuracy['stratified'] = dummy_clf_str.score(test_data, test_targets)\n",
        "\n",
        "print(\"Classification Accuracy for the Test Set \\n\")\n",
        "sorted_accuracy = [(k, test_accuracy[k]) for k in sorted(test_accuracy, key=test_accuracy.get, reverse=True)]\n",
        "print(\"Dummy Classifiers Scores\")\n",
        "for clf, score in sorted_accuracy:\n",
        "  print(str(clf) + \"\\t\\t: \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1yxnqAdSGh_",
        "outputId": "2b316395-c771-45b2-f531-8b82b67c2f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-macro score for the Test Set \n",
            "\n",
            "Dummy Classifiers Scores\n",
            "uniform \t\t:  0.4724025974025974\n",
            "stratified\t\t:  0.45054945054945056\n",
            "most frequent\t\t:  0.36708860759493667\n",
            "constant 1\t\t:  0.36708860759493667\n",
            "constant 0\t\t:  0.29577464788732394\n",
            "\n",
            "Dummy Classifiers Classification Reports\n",
            "\n",
            "uniform:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.43      0.41        21\n",
            "         1.0       0.56      0.52      0.54        29\n",
            "\n",
            "    accuracy                           0.48        50\n",
            "   macro avg       0.47      0.47      0.47        50\n",
            "weighted avg       0.49      0.48      0.48        50\n",
            "\n",
            "\n",
            "most frequent:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        21\n",
            "         1.0       0.58      1.00      0.73        29\n",
            "\n",
            "    accuracy                           0.58        50\n",
            "   macro avg       0.29      0.50      0.37        50\n",
            "weighted avg       0.34      0.58      0.43        50\n",
            "\n",
            "\n",
            "constant 0:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      1.00      0.59        21\n",
            "         1.0       0.00      0.00      0.00        29\n",
            "\n",
            "    accuracy                           0.42        50\n",
            "   macro avg       0.21      0.50      0.30        50\n",
            "weighted avg       0.18      0.42      0.25        50\n",
            "\n",
            "\n",
            "constant 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        21\n",
            "         1.0       0.58      1.00      0.73        29\n",
            "\n",
            "    accuracy                           0.58        50\n",
            "   macro avg       0.29      0.50      0.37        50\n",
            "weighted avg       0.34      0.58      0.43        50\n",
            "\n",
            "\n",
            "stratified:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.24      0.29        21\n",
            "         1.0       0.56      0.69      0.62        29\n",
            "\n",
            "    accuracy                           0.50        50\n",
            "   macro avg       0.46      0.46      0.45        50\n",
            "weighted avg       0.47      0.50      0.48        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification metrics for the test set\n",
        "test_predictions = {}\n",
        "test_f1 = {}\n",
        "#1\n",
        "test_predictions['uniform'] = dummy_clf_uniform.predict(test_data)\n",
        "test_f1['uniform '] = f1_score(y_test, test_predictions['uniform'], average='macro')\n",
        "#2\n",
        "test_predictions['most frequent'] = dummy_clf_mf.predict(test_data)\n",
        "test_f1['most frequent'] = f1_score(y_test, test_predictions['most frequent'], average='macro')\n",
        "#3\n",
        "test_predictions['constant 0'] = dummy_clf_constant_0.predict(test_data)\n",
        "test_f1['constant 0'] = f1_score(y_test, test_predictions['constant 0'], average='macro')\n",
        "test_predictions['constant 1'] = dummy_clf_constant_1.predict(test_data)\n",
        "test_f1['constant 1'] = f1_score(y_test, test_predictions['constant 1'], average='macro')\n",
        "#4\n",
        "test_predictions['stratified'] = dummy_clf_str.predict(test_data)\n",
        "test_f1['stratified'] = f1_score(y_test, test_predictions['stratified'], average='macro')\n",
        "\n",
        "print(\"F1-macro score for the Test Set \\n\")\n",
        "\n",
        "sorted_f1 = [(k, test_f1[k]) for k in sorted(test_f1, key=test_f1.get, reverse=True)]\n",
        "print(\"Dummy Classifiers Scores\")\n",
        "for clf, score in sorted_f1:\n",
        "  print(str(clf) + \"\\t\\t: \", score)\n",
        "\n",
        "print(\"\\nDummy Classifiers Classification Reports\\n\")\n",
        "\n",
        "print('uniform:\\n'+ classification_report(test_targets, test_predictions['uniform'], zero_division=0) +'\\n')\n",
        "print('most frequent:\\n'+ classification_report(test_targets, test_predictions['most frequent'], zero_division=0)+'\\n')\n",
        "print('constant 0:\\n'+ classification_report(test_targets, test_predictions['constant 0'], zero_division=0)+'\\n')\n",
        "print('constant 1:\\n'+ classification_report(test_targets, test_predictions['constant 1'], zero_division=0)+'\\n')\n",
        "print('stratified:\\n'+ classification_report(test_targets, test_predictions['stratified'], zero_division=0)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-espkQvNOdWh"
      },
      "source": [
        "### Gaussian Naive Bayes (GNB) Classifier\n",
        "Ελέγχουμε αρχικά την out-of-the-box επίδοση του αλγορίθμου Gaussian Naive Bayes, δηλαδή με τις default παραμέτρους του, με χρήση 10-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Mq01YZOoHL",
        "outputId": "c3c67f54-f865-4982-94f8-6e7c5b5c8985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "GNB accuracy:  0.7060606060606062\n",
            "GNB f1:  0.6378699907763374\n",
            "\n",
            "Test set:\n",
            "GNB accuracy:  0.66\n",
            "GNB f1:  0.6263736263736264\n",
            "\n",
            "GNB Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.43      0.51        21\n",
            "         1.0       0.67      0.83      0.74        29\n",
            "\n",
            "    accuracy                           0.66        50\n",
            "   macro avg       0.65      0.63      0.63        50\n",
            "weighted avg       0.66      0.66      0.64        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Model creation and training\n",
        "gnb_clf = GaussianNB()\n",
        "gnb_clf.fit(train_data, train_targets.values.ravel())\n",
        "\n",
        "# 10-cross validation\n",
        "gnb_accuracy_train = cross_val_score(gnb_clf, x_train, y_train, scoring='accuracy', cv = 10)\n",
        "gnb_f1_train = cross_val_score(gnb_clf, x_train, y_train, scoring='f1_macro', cv = 10)\n",
        "\n",
        "#Training set accuracy and f1-macro score\n",
        "print(\"Training Set:\")\n",
        "print(\"GNB accuracy: \", np.mean(gnb_accuracy_train))\n",
        "print(\"GNB f1: \", np.mean(gnb_f1_train))\n",
        "\n",
        "#Test set accuracy and f1-macro score\n",
        "gnb_accuracy_test = gnb_clf.score(x_test, y_test)\n",
        "gnb_predictions = gnb_clf.predict(x_test)\n",
        "gnb_f1_test = knn_f1 = f1_score(y_test, gnb_predictions, average='macro')\n",
        "\n",
        "print(\"\\nTest set:\")\n",
        "print(\"GNB accuracy: \", gnb_accuracy_test)\n",
        "print(\"GNB f1: \", gnb_f1_test)\n",
        "print('\\nGNB Classification Report:\\n' + classification_report(y_test, gnb_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6z8F_n2WllL"
      },
      "source": [
        "### K Nearest Neighbors (ΚNN)\n",
        "Ελέγχουμε αρχικά την out-of-the-box επίδοση του αλγορίθμου kNearestNeighbors, δηλαδή με τις default παραμέτρους του, με χρήση 10-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483rRwMHWhgz",
        "outputId": "90cbf188-5cdf-4db9-b60b-56cf3c9f3d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "kNN accuracy:  0.5681818181818181\n",
            "kNN f1 macro:  0.453828566514325\n",
            "\n",
            "Test set:\n",
            "kNN accuracy:  0.58\n",
            "kNN f1 macro:  0.5091164095371669\n",
            "\n",
            "kNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.24      0.32        21\n",
            "         1.0       0.60      0.83      0.70        29\n",
            "\n",
            "    accuracy                           0.58        50\n",
            "   macro avg       0.55      0.53      0.51        50\n",
            "weighted avg       0.56      0.58      0.54        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "# Classifier Creation and Training\n",
        "kNN_clf = neighbors.KNeighborsClassifier()\n",
        "kNN_clf.fit(train_data, train_targets.values.ravel())\n",
        "\n",
        "# Use of 10-fold cv for accuracy and f1-macro score for training set\n",
        "kNN_accuracy_train = cross_val_score(kNN_clf, x_train, y_train, scoring='accuracy' ,cv = 10)\n",
        "kNN_f1_train = cross_val_score(kNN_clf, x_train, y_train, scoring='f1_macro', cv = 10)\n",
        "\n",
        "# Training set accuracy and f1-macro score\n",
        "print(\"Training Set:\")\n",
        "print(\"kNN accuracy: \", np.mean(kNN_accuracy_train))\n",
        "print(\"kNN f1 macro: \", np.mean(kNN_f1_train))\n",
        "\n",
        "# Prediction on test data \n",
        "kNN_accuracy_test = kNN_clf.score(x_test, y_test)\n",
        "kNN_predictions = kNN_clf.predict(x_test)\n",
        "kNN_f1_test = f1_score(y_test, kNN_predictions, average='macro')\n",
        "\n",
        "# Test set accuracy and f1-macro score\n",
        "print(\"\\nTest set:\")\n",
        "print(\"kNN accuracy: \", kNN_accuracy_test)\n",
        "print(\"kNN f1 macro: \", kNN_f1_test)\n",
        "print('\\nkNN Classification Report:\\n' + classification_report(y_test, kNN_predictions)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9c-aAkwblB0"
      },
      "source": [
        "### Logistic Regression (LR)\n",
        "Ελέγχουμε αρχικά την out-of-the-box επίδοση του αλγορίθμου Logistic Reggression, δηλαδή με τις default παραμέτρους του, με χρήση 10-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYBCX066bsXp",
        "outputId": "b06d091d-9ac2-46d0-b46a-9bdd78f017dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "LR accuracy:  0.7303030303030303\n",
            "LR f1 macro:  0.6770066710894884\n",
            "\n",
            "Test set:\n",
            "LR accuracy:  0.68\n",
            "LR f1 macro:  0.6604414261460102\n",
            "\n",
            "LR Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.52      0.58        21\n",
            "         1.0       0.70      0.79      0.74        29\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.67      0.66      0.66        50\n",
            "weighted avg       0.68      0.68      0.67        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "\n",
        "# Classifier Creation and Training\n",
        "\n",
        "# Κάνουμε supress τα warnings καθώς αυτά που προκύπτουν είναι μόνο λόγο τις παραμέτρου max_iter  \n",
        "# Η default τιμή της είναι 100 και δεν αρκεί ώστε να συγκλίνει το μοντέλο σε ορισμένες περιπτώσεις\n",
        "\n",
        "with warnings.catch_warnings(record=True): \n",
        "  LR_clf = LogisticRegression()\n",
        "\n",
        "LR_clf.fit(train_data, train_targets.values.ravel())\n",
        "\n",
        "# Use of 10-fold cv for accuracy and f1-macro score for training set\n",
        "with warnings.catch_warnings(record=True): \n",
        "  LR_accuracy_train = cross_val_score(LR_clf, x_train, y_train, scoring='accuracy' ,cv = 10)\n",
        "  LR_f1_train = cross_val_score(LR_clf, x_train, y_train, scoring='f1_macro', cv = 10)\n",
        "\n",
        "# Training set accuracy and f1-macro score\n",
        "print(\"Training Set:\")\n",
        "print(\"LR accuracy: \", np.mean(LR_accuracy_train))\n",
        "print(\"LR f1 macro: \", np.mean(LR_f1_train))\n",
        "\n",
        "# Prediction on test data \n",
        "LR_accuracy_test = LR_clf.score(x_test, y_test)\n",
        "LR_predictions = LR_clf.predict(x_test)\n",
        "LR_f1_test = f1_score(y_test, LR_predictions, average='macro')\n",
        "\n",
        "# Test set accuracy and f1-macro score\n",
        "print(\"\\nTest set:\")\n",
        "print(\"LR accuracy: \", LR_accuracy_test)\n",
        "print(\"LR f1 macro: \", LR_f1_test)\n",
        "print('\\nLR Classification Report:\\n' + classification_report(y_test, LR_predictions)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_9kYdIMCvng"
      },
      "source": [
        "### Plots & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "3lMNFynyOj5T"
      },
      "outputs": [],
      "source": [
        "# Function to add value labels\n",
        "def addlabels(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i,y[i]+0.02,y[i],ha = 'center')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EtE6TqHDTGj"
      },
      "source": [
        "**Accuracy Diagram**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "dLLbvoBWDA68",
        "outputId": "8057c62d-b5f1-4d02-eeb8-19bd179130f0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_ootb_accuracy = {\n",
        "    'Dummy': max(test_accuracy.values()), \n",
        "    'GNB': gnb_accuracy_test, \n",
        "    'KNN': kNN_accuracy_test, \n",
        "    'LR': LR_accuracy_test, \n",
        "}\n",
        "\n",
        "classifiers = list(data_ootb_accuracy.keys())\n",
        "values_acc = list(data_ootb_accuracy.values())\n",
        "\n",
        "fig = plt.figure(figsize = (10, 4))\n",
        "plt.bar(classifiers, values_acc, color ='g', width = 0.4)\n",
        "\n",
        "plt.xlabel('Classifer', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('Accuracy score', fontweight ='bold', fontsize = 15)\n",
        "\n",
        "plt.ylim(0.0, 1.0) # Set min, max classifier scores\n",
        "addlabels(classifiers, values_acc)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuOJhoHgDY-1"
      },
      "source": [
        "**F1 Diagram**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "DIevoXqMGRzm",
        "outputId": "a9106d32-cbbf-4aca-c30a-40bcbdbe3b9f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_ootb_accuracy = {\n",
        "    'Dummy': np.round(max(test_f1.values()), 2), \n",
        "    'GNB': np.round(gnb_f1_test, 2), \n",
        "    'KNN': np.round(kNN_f1_test, 2), \n",
        "    'LR': np.round(LR_f1_test, 2), \n",
        "}\n",
        "\n",
        "classifiers = list(data_ootb_accuracy.keys())\n",
        "values_f1 = list(data_ootb_accuracy.values())\n",
        "\n",
        "fig = plt.figure(figsize = (10, 4))\n",
        "plt.bar(classifiers, values_f1, color ='g', width = 0.4)\n",
        "\n",
        "plt.xlabel('Classifer', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('F1 score', fontweight ='bold', fontsize = 15)\n",
        "\n",
        "plt.ylim(0.0, 1.0) # Set min, max classifier scores\n",
        "addlabels(classifiers, values_f1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GPhbOjqCe-r"
      },
      "source": [
        "**Σχολιασμός Επίδοσης Out-of-the-box Αλγορίθμων** <br> <br>\n",
        "Παρατηρούμε ότι οι ταξινομητές με τις default τιμές για τις παραμέτρους τους, σημειώνουν καλύτερη επίδοση από τους Dummy Classifiers το οποίο σημαίνει πως τα δεδομένα έχουν προετοιμαστεί και επεξεργαστεί σωστά.<br>\n",
        " Classifier | Accuracy | f1 score |\n",
        "| --- | :---: | :---: |\n",
        "| Dummy | 58 % | 47.2% |\n",
        "| Gausian Naive Bayes | 66 % | 62.6 % |\n",
        "| Knn | 58 % | 50.9 % |\n",
        "| Knn | 68 % | 66.1 % |\n",
        "\n",
        "\n",
        "Βέβαια η διαφορά δεν είναι μεγάλη και χρειάζεται επιπλέον επεξεργασία των δεδομένων (preprocessing) αλλά και εύρεση των βέλτιστων τιμών των υπερπαραμέτρων των ταξινομητών. Τότε θα παρατηρήσουμε μεγάλη διαφορά στις αποδόσεις των 'έξυπνων' ταξινομητών.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2kpgHJqNFF_"
      },
      "source": [
        "## Optimization\n",
        "1. Preproccessing\n",
        "  - Normalization\n",
        "  - Feature Selection\n",
        "  - Dataset balancing\n",
        "2. Pipelines declaration\n",
        "3. Optimal hyperparameters with grid search and cross-validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "_jK36BzpaC8u"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "import time \n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVNwh7DvFfzN"
      },
      "source": [
        "**Preproccessing**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "5_biK1qEc5bq"
      },
      "outputs": [],
      "source": [
        "x_train = train_data; y_train = train_targets.values.ravel()\n",
        "x_test = test_data; y_test = test_targets.values.ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkeL-28TFnY8"
      },
      "source": [
        "**Normalization**\n",
        "\n",
        "Θα χρησιμοποιήσουμε τον [Min-Max scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) για να κανονικοποιήσουμε τα δεδομένα μας στα train και test data set από το 0-1 ώστε όλα να έχουν την ίδια επίδραση στην εκπαίδευση του μοντέλου μας.\n",
        "\n",
        "_(Μπορούμε να χρησιμοποιήσουμε και τον [Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), ο οποίος θεωρεί ομαλή κατανομή στις τιμές των χαρακτηριστικών. Ωστόσο εμείς επιλέγουμε τον min-max γιατί δεν επηρεάζει τις binary μεταβλητές)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yUr7AW4FmVF",
        "outputId": "ee10bf29-7a5d-4878-d91e-279da0e4f625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.   0.   1.   ... 0.4  0.37 0.19]\n",
            " [1.   1.   1.   ... 0.4  0.37 0.19]\n",
            " [1.   1.   1.   ... 0.38 0.75 0.45]\n",
            " ...\n",
            " [1.   1.   1.   ... 0.4  0.37 0.19]\n",
            " [1.   1.   1.   ... 0.53 0.98 0.74]\n",
            " [0.   1.   0.   ... 0.4  0.37 0.19]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# Train set Normalization \n",
        "scaler.fit(train_data)\n",
        "x_train_normalized = np.round(scaler.transform(train_data), 2)\n",
        "# Test set Normalization\n",
        "scaler.fit(test_data)\n",
        "x_test_normalized = np.round(scaler.transform(test_data), 2)\n",
        "\n",
        "print(x_test_normalized)\n",
        "\n",
        "# x_train = x_train_normalized\n",
        "# x_test = x_test_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RovhOFZGWhfB"
      },
      "source": [
        "**Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH1R86gXWlYS",
        "outputId": "15007e21-697f-4b52-e26c-14f88f3e4600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial characteristics:  49\n",
            "New characteristics:  24\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "selector = VarianceThreshold(threshold=0.3)\n",
        "# Reduce characteristics in Train Set\n",
        "x_train_reduced = selector.fit_transform(x_train)\n",
        "# Apply mask to Test Set\n",
        "mask = selector.get_support()\n",
        "x_test_reduced = x_test.values[:,mask]\n",
        "\n",
        "print(\"Initial characteristics: \", np.shape(train_data)[1])\n",
        "print(\"New characteristics: \", np.shape(x_train_reduced)[1])\n",
        "\n",
        "x_train = x_train_reduced\n",
        "x_test = x_test_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlZB1oEvWly5"
      },
      "source": [
        "**Dataset balancing**\n",
        "\n",
        "Χρησιμοποιούμε oversampling στα δεδομένα της μικρότερης κλάσης. Τα αρχικά δεδομένα δεν είναι πολλά οπότε θέλουμε να αποφύγουμε να κάνουμε undersampling στα δεδομένα της μεγαλύτερης κλάσης. Σημειώνεται επίσης, ότι ο λόγος της πληθηκότητας των δύο κλάσεων είναι μικρότερος από 2/3 οπότε δεν περιμένουμε να επηρεάσει αυτό το optimization κατά πολύ τα αποτελέσματά μας.\n",
        "\n",
        "_Χρησιμοποιήσαμε τον_ [Random Oversampler](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FxpXfAsWqA8",
        "outputId": "7e08464c-81f4-45c0-944d-caeeb1b5d088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Dataset Size :\n",
            "Total:  115\n",
            "Class 0:  44\n",
            "Class 1:  71\n"
          ]
        }
      ],
      "source": [
        "print(\"Current Dataset Size :\")\n",
        "print(\"Total: \", np.shape(train_targets)[0])\n",
        "print(\"Class 0: \", np.count_nonzero(train_targets == 0))\n",
        "print(\"Class 1: \", np.count_nonzero(train_targets == 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSsYfBgFZZg4",
        "outputId": "d6a496a2-28ef-40c2-c54f-97f6ac384275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Dataset Size :\n",
            "Total:  142\n",
            "Class 0:  71\n",
            "Class 1:  71\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler()\n",
        "x_train_res, y_train_res = ros.fit_resample(x_train, y_train)\n",
        "print(\"New Dataset Size :\")\n",
        "print(\"Total: \", np.shape(y_train_res)[0])\n",
        "print(\"Class 0: \", np.count_nonzero(y_train_res == 0))\n",
        "print(\"Class 1: \", np.count_nonzero(y_train_res == 1))\n",
        "\n",
        "x_train = x_train_res\n",
        "y_train = y_train_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlqHmu3yOdXP"
      },
      "source": [
        "### Dummy Classifier\n",
        "\n",
        "Για τον dummy ταξινομητή δεν μπορεί να γίνει κάποια βελτιστοποίηση καθώς οι έξοδοι είναι ανεξάρτητοι της ποιότητας των δεδομένων και χρησιμοποιείται για τον ορισμό ενός κάτω φράγματος όσον αφορά την απόδοση του μοντέλου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsHK2h0WOgXf"
      },
      "source": [
        "### Gaussian Naive Bayes (GNB) Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLEAYlsCapxh"
      },
      "source": [
        "**Βελτιστοποίηση βάσει του accuracy score.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "F88nnXm2jQor"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization using Optuna\n",
        "def gnb_objective_accuracy(trial):\n",
        "\n",
        "  scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust'])\n",
        "\n",
        "  if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "  elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "  else:\n",
        "        scaler = RobustScaler()\n",
        "\n",
        "  # Hyperparameters setting\n",
        "  var_smoothing = trial.suggest_float('var_smoothing', 0.5e-9, 2e-9)\n",
        "\n",
        "  # Pipeline creation\n",
        "  gnb = GaussianNB(var_smoothing=var_smoothing)\n",
        "  # Normalization + Model Creation\n",
        "  gnb_pipeline = make_pipeline(scaler, gnb)\n",
        "\n",
        "  # Model training with cv\n",
        "  score = cross_val_score(gnb_pipeline, x_train, y_train, scoring='accuracy', cv = 10, n_jobs = 1)\n",
        "  return score.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmgImFbgj36Y",
        "outputId": "4c13fc88-b5c1-40f3-897b-7e3959907381"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-27 10:25:18,966]\u001b[0m A new study created in memory with name: no-name-f80f5a34-5b0f-49ee-aad8-ed1e81f5c367\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:18,997]\u001b[0m Trial 0 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.397987726295555e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,023]\u001b[0m Trial 1 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.799264218662403e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,052]\u001b[0m Trial 2 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.9548647782429917e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,077]\u001b[0m Trial 3 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 7.751067647801508e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,105]\u001b[0m Trial 4 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 9.36843710297063e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,134]\u001b[0m Trial 5 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.0495427649405376e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,161]\u001b[0m Trial 6 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2713516576204174e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,213]\u001b[0m Trial 7 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.557861855309373e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,271]\u001b[0m Trial 8 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.7125960221746919e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,322]\u001b[0m Trial 9 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1602287406094022e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,354]\u001b[0m Trial 10 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4807272134327033e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,385]\u001b[0m Trial 11 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.5511993117875338e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,414]\u001b[0m Trial 12 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8614971929237771e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,442]\u001b[0m Trial 13 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.412993887560281e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,473]\u001b[0m Trial 14 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.197650986950108e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,501]\u001b[0m Trial 15 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7061002521272418e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,544]\u001b[0m Trial 16 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6923782452741103e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,575]\u001b[0m Trial 17 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.30045716227062e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,606]\u001b[0m Trial 18 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.3172938730276616e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,636]\u001b[0m Trial 19 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5948606295415028e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,668]\u001b[0m Trial 20 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.190488753479305e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,700]\u001b[0m Trial 21 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3106099096543073e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,736]\u001b[0m Trial 22 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4291239006817256e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,767]\u001b[0m Trial 23 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5679667033201176e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,797]\u001b[0m Trial 24 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.1848150349764441e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,828]\u001b[0m Trial 25 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4084386958879408e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,858]\u001b[0m Trial 26 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5800600221070076e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,923]\u001b[0m Trial 27 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0959100315527474e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,954]\u001b[0m Trial 28 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2051007300097287e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:19,985]\u001b[0m Trial 29 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.8194208900897693e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,044]\u001b[0m Trial 30 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0650115122784871e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,102]\u001b[0m Trial 31 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.52466922683714e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,168]\u001b[0m Trial 32 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.953512745951692e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,226]\u001b[0m Trial 33 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.664523082837961e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,282]\u001b[0m Trial 34 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.330723150375405e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,320]\u001b[0m Trial 35 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3157615411800189e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,352]\u001b[0m Trial 36 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3974433246424017e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,384]\u001b[0m Trial 37 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 6.116819147231978e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,415]\u001b[0m Trial 38 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5140674503179649e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,447]\u001b[0m Trial 39 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6264958540187892e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,480]\u001b[0m Trial 40 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2245290292100993e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,511]\u001b[0m Trial 41 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.429108577815067e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,543]\u001b[0m Trial 42 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.642421531109817e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,576]\u001b[0m Trial 43 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5208866811705468e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,633]\u001b[0m Trial 44 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.121154550740536e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,689]\u001b[0m Trial 45 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0977966541439956e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,720]\u001b[0m Trial 46 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2251798216100034e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,785]\u001b[0m Trial 47 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.3568764731494126e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,814]\u001b[0m Trial 48 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.827093581532323e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,847]\u001b[0m Trial 49 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.75987686700821e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,902]\u001b[0m Trial 50 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0122302679860535e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:20,965]\u001b[0m Trial 51 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.058182311908794e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,022]\u001b[0m Trial 52 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.8859453589651355e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,080]\u001b[0m Trial 53 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.972253819950142e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,135]\u001b[0m Trial 54 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.007717042740931e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,191]\u001b[0m Trial 55 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.494963086127064e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,247]\u001b[0m Trial 56 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.77172582435738e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,299]\u001b[0m Trial 57 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.40353561411811e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,353]\u001b[0m Trial 58 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.093294999996829e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,417]\u001b[0m Trial 59 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.734171756628585e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,450]\u001b[0m Trial 60 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.2791372610621543e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,482]\u001b[0m Trial 61 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 6.316861000092228e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,515]\u001b[0m Trial 62 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 6.177346144363684e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,549]\u001b[0m Trial 63 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3442462504604712e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,580]\u001b[0m Trial 64 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.480342851226284e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,612]\u001b[0m Trial 65 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6429871537611152e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,651]\u001b[0m Trial 66 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.492595374775144e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,682]\u001b[0m Trial 67 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3893051540581567e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,713]\u001b[0m Trial 68 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4513382389996573e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,745]\u001b[0m Trial 69 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.537328177603912e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,777]\u001b[0m Trial 70 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6868562491285743e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,809]\u001b[0m Trial 71 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.1527073070649304e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,840]\u001b[0m Trial 72 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9015064761164458e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,870]\u001b[0m Trial 73 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.906781730574827e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,926]\u001b[0m Trial 74 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.7692431139987524e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:21,997]\u001b[0m Trial 75 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.792075772486021e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,056]\u001b[0m Trial 76 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9816135807661045e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,112]\u001b[0m Trial 77 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0365556396339277e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,168]\u001b[0m Trial 78 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.008422654529632e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,225]\u001b[0m Trial 79 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.973876393879931e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,285]\u001b[0m Trial 80 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.720476723038605e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,341]\u001b[0m Trial 81 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.080568459854603e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,399]\u001b[0m Trial 82 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.280703772735195e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,471]\u001b[0m Trial 83 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 6.863517571077214e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,529]\u001b[0m Trial 84 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.746043458446278e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,593]\u001b[0m Trial 85 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.226035553455656e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,625]\u001b[0m Trial 86 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.78560422104032e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,655]\u001b[0m Trial 87 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.906198022468098e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,686]\u001b[0m Trial 88 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.887149529022756e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,719]\u001b[0m Trial 89 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.465049372903793e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,751]\u001b[0m Trial 90 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2657948140771854e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,783]\u001b[0m Trial 91 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2899526634220362e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,815]\u001b[0m Trial 92 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4741625923430695e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,849]\u001b[0m Trial 93 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.529790317349601e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,880]\u001b[0m Trial 94 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3665151245842661e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,912]\u001b[0m Trial 95 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.464524107518079e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,944]\u001b[0m Trial 96 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5354280860266138e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:22,982]\u001b[0m Trial 97 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6167500600425112e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,014]\u001b[0m Trial 98 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6601436547878437e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,046]\u001b[0m Trial 99 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5704301048689618e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,077]\u001b[0m Trial 100 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.501920913090857e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,109]\u001b[0m Trial 101 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3693695629642546e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,142]\u001b[0m Trial 102 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.898031132065442e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,173]\u001b[0m Trial 103 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7334271926797337e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,218]\u001b[0m Trial 104 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.787625400432581e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,248]\u001b[0m Trial 105 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9192378047439286e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,282]\u001b[0m Trial 106 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8288746705848817e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,318]\u001b[0m Trial 107 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.999771888296951e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,377]\u001b[0m Trial 108 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1693139093771105e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,432]\u001b[0m Trial 109 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.8580452333629334e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,489]\u001b[0m Trial 110 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1347759085758215e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,545]\u001b[0m Trial 111 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0132676935067117e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,602]\u001b[0m Trial 112 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.930060444408205e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,656]\u001b[0m Trial 113 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.11356330695045e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,711]\u001b[0m Trial 114 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.737492197238477e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,767]\u001b[0m Trial 115 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.352992040966779e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,825]\u001b[0m Trial 116 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.114828456373338e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,880]\u001b[0m Trial 117 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.132246759999535e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:23,939]\u001b[0m Trial 118 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.68183166465323e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,005]\u001b[0m Trial 119 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 6.684569890815244e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,061]\u001b[0m Trial 120 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 6.888862216175515e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,127]\u001b[0m Trial 121 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.078728840434017e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,183]\u001b[0m Trial 122 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.684074212087943e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,213]\u001b[0m Trial 123 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.785525690195358e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,242]\u001b[0m Trial 124 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.873765447799066e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,274]\u001b[0m Trial 125 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.541719530530726e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,304]\u001b[0m Trial 126 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.072570995545952e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,336]\u001b[0m Trial 127 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.2823789577228483e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,365]\u001b[0m Trial 128 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.669497418683468e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,399]\u001b[0m Trial 129 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.426809209849366e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,432]\u001b[0m Trial 130 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3283720090816818e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,464]\u001b[0m Trial 131 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.578680574831137e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,498]\u001b[0m Trial 132 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.434271722371681e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,533]\u001b[0m Trial 133 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2486929038409255e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,565]\u001b[0m Trial 134 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3856246000588279e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,597]\u001b[0m Trial 135 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 5.380362744436256e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,629]\u001b[0m Trial 136 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.560523543771092e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,661]\u001b[0m Trial 137 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5907451180363935e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,693]\u001b[0m Trial 138 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4709443195991916e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,729]\u001b[0m Trial 139 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5107744857366541e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,765]\u001b[0m Trial 140 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3570654010888662e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,795]\u001b[0m Trial 141 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.618230833690954e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,828]\u001b[0m Trial 142 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.671026145238343e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,862]\u001b[0m Trial 143 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.7375746055953254e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,894]\u001b[0m Trial 144 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.7212323026313244e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,926]\u001b[0m Trial 145 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.456469816035802e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,961]\u001b[0m Trial 146 finished with value: 0.6971428571428571 and parameters: {'scalers': 'standard', 'var_smoothing': 1.8163815671655375e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:24,991]\u001b[0m Trial 147 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8666472857345564e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,028]\u001b[0m Trial 148 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9355590313709397e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,065]\u001b[0m Trial 149 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.5322262783417787e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,094]\u001b[0m Trial 150 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8332164164925069e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,124]\u001b[0m Trial 151 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.156353177764134e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,153]\u001b[0m Trial 152 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8587448863225e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,186]\u001b[0m Trial 153 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7736637345820968e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,220]\u001b[0m Trial 154 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9389894256596695e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,251]\u001b[0m Trial 155 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9817380035176244e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,309]\u001b[0m Trial 156 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9278291846843085e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,341]\u001b[0m Trial 157 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.892792047077918e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,398]\u001b[0m Trial 158 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1023377705890934e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,429]\u001b[0m Trial 159 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.046374069808449e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,486]\u001b[0m Trial 160 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.538274555740363e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,543]\u001b[0m Trial 161 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.857163131730482e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,599]\u001b[0m Trial 162 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.355703221582795e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,667]\u001b[0m Trial 163 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.370183391623113e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,724]\u001b[0m Trial 164 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.040621895278301e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,779]\u001b[0m Trial 165 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9994178994942914e-09}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,835]\u001b[0m Trial 166 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.05895300728411e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,893]\u001b[0m Trial 167 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.915752053962511e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:25,952]\u001b[0m Trial 168 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.025687400538566e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,008]\u001b[0m Trial 169 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 9.829643141900045e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,074]\u001b[0m Trial 170 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.81345408442584e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,130]\u001b[0m Trial 171 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 8.468978095653126e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,186]\u001b[0m Trial 172 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 6.717314152419307e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,243]\u001b[0m Trial 173 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.581940407545542e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,305]\u001b[0m Trial 174 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 5.917561660255697e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,367]\u001b[0m Trial 175 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 5.095068909328564e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,424]\u001b[0m Trial 176 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 5.690347482124952e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,481]\u001b[0m Trial 177 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 6.701778376479886e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,512]\u001b[0m Trial 178 finished with value: 0.6971428571428571 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.311507210417712e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,571]\u001b[0m Trial 179 finished with value: 0.6971428571428571 and parameters: {'scalers': 'robust', 'var_smoothing': 7.136415000408167e-10}. Best is trial 0 with value: 0.6971428571428571.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "gnb_sampler = TPESampler(seed=42) # create a seed for the sampler for reproducibility\n",
        "gnb_study = optuna.create_study(direction=\"maximize\", sampler=gnb_sampler)\n",
        "gnb_study.optimize(gnb_objective_accuracy, n_trials=180)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "DNhHsO8LaM1x",
        "outputId": "f9fea0cb-6367-4710-abc3-7d6e5f67dc56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"50a47d3d-8e55-4ef9-aa45-9e1fe4703656\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50a47d3d-8e55-4ef9-aa45-9e1fe4703656\")) {                    Plotly.newPlot(                        \"50a47d3d-8e55-4ef9-aa45-9e1fe4703656\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179],\"y\":[0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179],\"y\":[0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571,0.6971428571428571],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('50a47d3d-8e55-4ef9-aa45-9e1fe4703656');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(gnb_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQg6NjWRaaV4",
        "outputId": "17857cef-d192-4f1b-ef10-b716d30dee66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters after tuning using mean accuracy:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'scalers': 'standard', 'var_smoothing': 1.397987726295555e-09}"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Best parameters after tuning using mean accuracy:\")\n",
        "gnb_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G71kf9UlM1EI",
        "outputId": "366f45fd-e756-4e8b-e5c1-58eca4a269be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος train και test: 0.06442856788635254 seconds\n",
            "Training Set:\n",
            "GNB accuracy:  0.6971428571428571\n",
            "GNB f1:  0.6971428571428571\n",
            "\n",
            "Testing set:\n",
            "GNB accuracy:  0.68\n",
            "GNB f1:  0.6604414261460102\n",
            "\n",
            "GNB Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.52      0.58        21\n",
            "         1.0       0.70      0.79      0.74        29\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.67      0.66      0.66        50\n",
            "weighted avg       0.68      0.68      0.67        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use the best hyperparameters to train the model again\n",
        "best_params = gnb_study.best_params\n",
        "\n",
        "if best_params['scalers'] == \"minmax\":\n",
        "  opt_scaler = MinMaxScaler()\n",
        "elif best_params['scalers'] == \"standard\":\n",
        "  opt_scaler = StandardScaler()\n",
        "else:\n",
        "  opt_scaler = RobustScaler()\n",
        "\n",
        "del best_params['scalers']\n",
        "\n",
        "# Creation of gnb classifier with optimized parameters\n",
        "gnb_clf_opt = GaussianNB(**best_params)\n",
        "gnb_pipeline = make_pipeline(opt_scaler, gnb_clf_opt)\n",
        "\n",
        "# Kαταγραφή χρόνου train και test\n",
        "start_time = time.time()\n",
        "\n",
        "# Model training \n",
        "strtfdKFold = StratifiedKFold(n_splits=10)\n",
        "gnb_pipeline.fit(x_train, y_train)\n",
        "gnb_accuracy_train = cross_val_score(gnb_pipeline, x_train, y_train, scoring='accuracy' ,cv = strtfdKFold, n_jobs=1)\n",
        "gnb_f1_train = cross_val_score(gnb_pipeline, x_train, y_train, scoring='f1_macro', cv = strtfdKFold, n_jobs=1)\n",
        "\n",
        "# Testing\n",
        "gnb_acc_test = gnb_pipeline.score(x_test, y_test)\n",
        "gnb_predictions = gnb_pipeline.predict(x_test)\n",
        "gnb_f1_test = f1_score(y_test, gnb_predictions, average='macro')\n",
        "\n",
        "# Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(\"GNB accuracy: \", gnb_accuracy_train.mean())\n",
        "print(\"GNB f1: \", gnb_accuracy_train.mean())\n",
        "\n",
        "print(\"\\nTesting set:\")\n",
        "print(\"GNB accuracy: \", gnb_acc_test)\n",
        "print(\"GNB f1: \", gnb_f1_test)\n",
        "print('\\nGNB Classification Report:\\n' + classification_report(y_test, gnb_predictions)+'\\n')\n",
        "\n",
        "# Save the results for the optimization using ACCURACY\n",
        "gnb_accuracy_ACC = gnb_acc_test\n",
        "gnb_f1_ACC = gnb_f1_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYRCM9jTalk8"
      },
      "source": [
        "**Βελτιστοποίηση βάσει του f1-macro score.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "F-xmN9YGax7s"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization using Optuna\n",
        "def gnb_objective_f1(trial):\n",
        "\n",
        "  # Hyperparameters setting\n",
        "  scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust'])\n",
        "\n",
        "  if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "  elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "  else:\n",
        "        scaler = RobustScaler()\n",
        "        \n",
        "  var_smoothing = trial.suggest_float('var_smoothing', 0.5e-9, 2e-9)\n",
        "\n",
        "  # Pipeline Creation\n",
        "  gnb = GaussianNB(var_smoothing=var_smoothing)\n",
        "  # Normalization + Model Creation\n",
        "  gnb_pipeline = make_pipeline(scaler, gnb)\n",
        "\n",
        "  start_time = time.time()\n",
        "  # Model training with cv\n",
        "  score = cross_val_score(gnb_pipeline, x_train, y_train, scoring='f1_macro', cv = 10, n_jobs = 1)\n",
        "  score_mean = score.mean()\n",
        "  \n",
        "  return score_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiCyXzD3a9hA",
        "outputId": "1aa65a9f-8fd8-4311-9136-2481be9fd011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-27 10:25:26,734]\u001b[0m A new study created in memory with name: no-name-afefe617-f200-4291-a119-81a021eaa1be\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,772]\u001b[0m Trial 0 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.397987726295555e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,802]\u001b[0m Trial 1 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.799264218662403e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,836]\u001b[0m Trial 2 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.9548647782429917e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,881]\u001b[0m Trial 3 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 7.751067647801508e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,916]\u001b[0m Trial 4 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 9.36843710297063e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,949]\u001b[0m Trial 5 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.0495427649405376e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:26,984]\u001b[0m Trial 6 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2713516576204174e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,046]\u001b[0m Trial 7 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.557861855309373e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,109]\u001b[0m Trial 8 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.7125960221746919e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,167]\u001b[0m Trial 9 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1602287406094022e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,204]\u001b[0m Trial 10 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4807272134327033e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,241]\u001b[0m Trial 11 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.5511993117875338e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,278]\u001b[0m Trial 12 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8614971929237771e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,315]\u001b[0m Trial 13 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.412993887560281e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,352]\u001b[0m Trial 14 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.197650986950108e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,388]\u001b[0m Trial 15 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7061002521272418e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,426]\u001b[0m Trial 16 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6923782452741103e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,465]\u001b[0m Trial 17 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.30045716227062e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,513]\u001b[0m Trial 18 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.3172938730276616e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,554]\u001b[0m Trial 19 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5948606295415028e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,592]\u001b[0m Trial 20 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.190488753479305e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,630]\u001b[0m Trial 21 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3106099096543073e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,668]\u001b[0m Trial 22 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4291239006817256e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,709]\u001b[0m Trial 23 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5679667033201176e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,745]\u001b[0m Trial 24 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.1848150349764441e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,784]\u001b[0m Trial 25 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4084386958879408e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,823]\u001b[0m Trial 26 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5800600221070076e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,885]\u001b[0m Trial 27 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0959100315527474e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,923]\u001b[0m Trial 28 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2051007300097287e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:27,961]\u001b[0m Trial 29 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.8194208900897693e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,023]\u001b[0m Trial 30 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0650115122784871e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,094]\u001b[0m Trial 31 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.52466922683714e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,165]\u001b[0m Trial 32 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.953512745951692e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,226]\u001b[0m Trial 33 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.664523082837961e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,286]\u001b[0m Trial 34 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.330723150375405e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,326]\u001b[0m Trial 35 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3157615411800189e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,364]\u001b[0m Trial 36 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3974433246424017e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,403]\u001b[0m Trial 37 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 6.116819147231978e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,442]\u001b[0m Trial 38 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5140674503179649e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,480]\u001b[0m Trial 39 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6264958540187892e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,519]\u001b[0m Trial 40 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2245290292100993e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,557]\u001b[0m Trial 41 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.429108577815067e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,595]\u001b[0m Trial 42 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.642421531109817e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,633]\u001b[0m Trial 43 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5208866811705468e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,711]\u001b[0m Trial 44 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.121154550740536e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,803]\u001b[0m Trial 45 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0977966541439956e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,848]\u001b[0m Trial 46 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2251798216100034e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,919]\u001b[0m Trial 47 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.3568764731494126e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:28,960]\u001b[0m Trial 48 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.827093581532323e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,002]\u001b[0m Trial 49 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.75987686700821e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,075]\u001b[0m Trial 50 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0122302679860535e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,152]\u001b[0m Trial 51 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.058182311908794e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,221]\u001b[0m Trial 52 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.8859453589651355e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,286]\u001b[0m Trial 53 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.972253819950142e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,364]\u001b[0m Trial 54 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.007717042740931e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,430]\u001b[0m Trial 55 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.494963086127064e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,495]\u001b[0m Trial 56 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.77172582435738e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,562]\u001b[0m Trial 57 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.40353561411811e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,624]\u001b[0m Trial 58 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.093294999996829e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,689]\u001b[0m Trial 59 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.734171756628585e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,728]\u001b[0m Trial 60 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.2791372610621543e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,767]\u001b[0m Trial 61 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 6.316861000092228e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,806]\u001b[0m Trial 62 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 6.177346144363684e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,845]\u001b[0m Trial 63 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3442462504604712e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,885]\u001b[0m Trial 64 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.480342851226284e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,925]\u001b[0m Trial 65 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6429871537611152e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:29,971]\u001b[0m Trial 66 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.492595374775144e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,013]\u001b[0m Trial 67 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3893051540581567e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,053]\u001b[0m Trial 68 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4513382389996573e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,095]\u001b[0m Trial 69 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.537328177603912e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,143]\u001b[0m Trial 70 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6868562491285743e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,181]\u001b[0m Trial 71 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.1527073070649304e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,223]\u001b[0m Trial 72 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9015064761164458e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,260]\u001b[0m Trial 73 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.906781730574827e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,324]\u001b[0m Trial 74 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.7692431139987524e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,385]\u001b[0m Trial 75 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.792075772486021e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,447]\u001b[0m Trial 76 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9816135807661045e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,510]\u001b[0m Trial 77 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0365556396339277e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,578]\u001b[0m Trial 78 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.008422654529632e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,641]\u001b[0m Trial 79 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.973876393879931e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,706]\u001b[0m Trial 80 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.720476723038605e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,768]\u001b[0m Trial 81 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.080568459854603e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,830]\u001b[0m Trial 82 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.280703772735195e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,892]\u001b[0m Trial 83 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 6.863517571077214e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:30,954]\u001b[0m Trial 84 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.746043458446278e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,019]\u001b[0m Trial 85 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.226035553455656e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,056]\u001b[0m Trial 86 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.78560422104032e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,094]\u001b[0m Trial 87 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.906198022468098e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,134]\u001b[0m Trial 88 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.887149529022756e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,189]\u001b[0m Trial 89 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.465049372903793e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,235]\u001b[0m Trial 90 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2657948140771854e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,277]\u001b[0m Trial 91 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2899526634220362e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,316]\u001b[0m Trial 92 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4741625923430695e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,355]\u001b[0m Trial 93 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.529790317349601e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,392]\u001b[0m Trial 94 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3665151245842661e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,429]\u001b[0m Trial 95 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.464524107518079e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,469]\u001b[0m Trial 96 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5354280860266138e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,509]\u001b[0m Trial 97 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6167500600425112e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,546]\u001b[0m Trial 98 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.6601436547878437e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,583]\u001b[0m Trial 99 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5704301048689618e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,624]\u001b[0m Trial 100 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.501920913090857e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,662]\u001b[0m Trial 101 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3693695629642546e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,697]\u001b[0m Trial 102 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.898031132065442e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,732]\u001b[0m Trial 103 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7334271926797337e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,770]\u001b[0m Trial 104 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.787625400432581e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,807]\u001b[0m Trial 105 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9192378047439286e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,844]\u001b[0m Trial 106 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8288746705848817e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,886]\u001b[0m Trial 107 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.999771888296951e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:31,950]\u001b[0m Trial 108 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1693139093771105e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,010]\u001b[0m Trial 109 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.8580452333629334e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,079]\u001b[0m Trial 110 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1347759085758215e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,143]\u001b[0m Trial 111 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.0132676935067117e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,214]\u001b[0m Trial 112 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.930060444408205e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,273]\u001b[0m Trial 113 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.11356330695045e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,335]\u001b[0m Trial 114 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.737492197238477e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,403]\u001b[0m Trial 115 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.352992040966779e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,464]\u001b[0m Trial 116 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.114828456373338e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,528]\u001b[0m Trial 117 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.132246759999535e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,591]\u001b[0m Trial 118 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.68183166465323e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,654]\u001b[0m Trial 119 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 6.684569890815244e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,725]\u001b[0m Trial 120 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 6.888862216175515e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,788]\u001b[0m Trial 121 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.078728840434017e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,848]\u001b[0m Trial 122 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.684074212087943e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,886]\u001b[0m Trial 123 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.785525690195358e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,922]\u001b[0m Trial 124 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.873765447799066e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:32,963]\u001b[0m Trial 125 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.541719530530726e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,001]\u001b[0m Trial 126 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.072570995545952e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,038]\u001b[0m Trial 127 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.2823789577228483e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,081]\u001b[0m Trial 128 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 5.669497418683468e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,124]\u001b[0m Trial 129 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.426809209849366e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,163]\u001b[0m Trial 130 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3283720090816818e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,211]\u001b[0m Trial 131 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.578680574831137e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,250]\u001b[0m Trial 132 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.434271722371681e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,291]\u001b[0m Trial 133 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.2486929038409255e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,332]\u001b[0m Trial 134 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3856246000588279e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,373]\u001b[0m Trial 135 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 5.380362744436256e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,412]\u001b[0m Trial 136 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.560523543771092e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,451]\u001b[0m Trial 137 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5907451180363935e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,489]\u001b[0m Trial 138 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.4709443195991916e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,527]\u001b[0m Trial 139 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.5107744857366541e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,566]\u001b[0m Trial 140 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.3570654010888662e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,603]\u001b[0m Trial 141 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.618230833690954e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,645]\u001b[0m Trial 142 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.671026145238343e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,684]\u001b[0m Trial 143 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.7375746055953254e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,724]\u001b[0m Trial 144 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.7212323026313244e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,759]\u001b[0m Trial 145 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.456469816035802e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,797]\u001b[0m Trial 146 finished with value: 0.688634487717305 and parameters: {'scalers': 'standard', 'var_smoothing': 1.8163815671655375e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,833]\u001b[0m Trial 147 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8666472857345564e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:33,871]\u001b[0m Trial 148 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9355590313709397e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,020]\u001b[0m Trial 149 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.5322262783417787e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,058]\u001b[0m Trial 150 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8332164164925069e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,096]\u001b[0m Trial 151 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.156353177764134e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,134]\u001b[0m Trial 152 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.8587448863225e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,169]\u001b[0m Trial 153 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.7736637345820968e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,212]\u001b[0m Trial 154 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9389894256596695e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,248]\u001b[0m Trial 155 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.9817380035176244e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,309]\u001b[0m Trial 156 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9278291846843085e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,346]\u001b[0m Trial 157 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.892792047077918e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,408]\u001b[0m Trial 158 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.1023377705890934e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,445]\u001b[0m Trial 159 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 1.046374069808449e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,509]\u001b[0m Trial 160 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.538274555740363e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,587]\u001b[0m Trial 161 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.857163131730482e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,661]\u001b[0m Trial 162 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.355703221582795e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,724]\u001b[0m Trial 163 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.370183391623113e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,789]\u001b[0m Trial 164 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.040621895278301e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,851]\u001b[0m Trial 165 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 1.9994178994942914e-09}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,914]\u001b[0m Trial 166 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.05895300728411e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:34,977]\u001b[0m Trial 167 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.915752053962511e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,039]\u001b[0m Trial 168 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.025687400538566e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,103]\u001b[0m Trial 169 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 9.829643141900045e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,166]\u001b[0m Trial 170 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.81345408442584e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,241]\u001b[0m Trial 171 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 8.468978095653126e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,303]\u001b[0m Trial 172 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 6.717314152419307e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,368]\u001b[0m Trial 173 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.581940407545542e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,429]\u001b[0m Trial 174 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 5.917561660255697e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,494]\u001b[0m Trial 175 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 5.095068909328564e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,556]\u001b[0m Trial 176 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 5.690347482124952e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,620]\u001b[0m Trial 177 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 6.701778376479886e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,658]\u001b[0m Trial 178 finished with value: 0.688634487717305 and parameters: {'scalers': 'minmax', 'var_smoothing': 6.311507210417712e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,720]\u001b[0m Trial 179 finished with value: 0.688634487717305 and parameters: {'scalers': 'robust', 'var_smoothing': 7.136415000408167e-10}. Best is trial 0 with value: 0.688634487717305.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "gnb_sampler = TPESampler(seed=42) # create a seed for the sampler for reproducibility\n",
        "gnb_study = optuna.create_study(direction=\"maximize\", sampler=gnb_sampler)\n",
        "gnb_study.optimize(gnb_objective_f1, n_trials=180)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "S_s4pyxybEtU",
        "outputId": "20c6cacf-1e58-4a5e-ead9-a0316d863ee5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d091fd37-be10-4e99-bb69-e679b5d90376\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d091fd37-be10-4e99-bb69-e679b5d90376\")) {                    Plotly.newPlot(                        \"d091fd37-be10-4e99-bb69-e679b5d90376\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179],\"y\":[0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179],\"y\":[0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305,0.688634487717305],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d091fd37-be10-4e99-bb69-e679b5d90376');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(gnb_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTTC3gX2bIOu",
        "outputId": "bbf04496-2101-4b6f-ba0c-2f20c762874f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters after tuning using mean accuracy:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'scalers': 'standard', 'var_smoothing': 1.397987726295555e-09}"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Best parameters after tuning using mean accuracy:\")\n",
        "gnb_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Hn3awSPmsP",
        "outputId": "6c1ac988-df61-4cca-e1b1-67ddb0ee71ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος train και test: 0.07065629959106445 seconds\n",
            "Training Set:\n",
            "GNB accuracy:  0.6971428571428571\n",
            "GNB f1:  0.6971428571428571\n",
            "\n",
            "Testing set:\n",
            "GNB accuracy:  0.68\n",
            "GNB f1:  0.6604414261460102\n",
            "\n",
            "GNB Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.52      0.58        21\n",
            "         1.0       0.70      0.79      0.74        29\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.67      0.66      0.66        50\n",
            "weighted avg       0.68      0.68      0.67        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use the best hyperparameters to train the model again\n",
        "best_params = gnb_study.best_params\n",
        "\n",
        "if best_params['scalers'] == \"minmax\":\n",
        "  opt_scaler = MinMaxScaler()\n",
        "elif best_params['scalers'] == \"standard\":\n",
        "  opt_scaler = StandardScaler()\n",
        "else:\n",
        "  opt_scaler = RobustScaler()\n",
        "\n",
        "del best_params['scalers']\n",
        "\n",
        "# Creation of gnb classifier with optimized parameters\n",
        "gnb_clf_opt = GaussianNB(**best_params)\n",
        "gnb_pipeline = make_pipeline(opt_scaler, gnb_clf_opt)\n",
        "\n",
        "# Kαταγραφή χρόνου train και test\n",
        "start_time = time.time()\n",
        "\n",
        "# Model training \n",
        "strtfdKFold = StratifiedKFold(n_splits=10)\n",
        "gnb_pipeline.fit(x_train, y_train)\n",
        "gnb_accuracy_train = cross_val_score(gnb_pipeline, x_train, y_train, scoring='accuracy' ,cv = strtfdKFold, n_jobs=1)\n",
        "gnb_f1_train = cross_val_score(gnb_pipeline, x_train, y_train, scoring='f1_macro', cv = strtfdKFold, n_jobs=1)\n",
        "\n",
        "# Model Testing\n",
        "gnb_acc_test = gnb_pipeline.score(x_test, y_test)\n",
        "gnb_predictions = gnb_pipeline.predict(x_test)\n",
        "gnb_f1_test = f1_score(y_test, gnb_predictions, average='macro')\n",
        "\n",
        "# Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(\"GNB accuracy: \", gnb_accuracy_train.mean())\n",
        "print(\"GNB f1: \", gnb_accuracy_train.mean())\n",
        "\n",
        "print(\"\\nTesting set:\")\n",
        "print(\"GNB accuracy: \", gnb_acc_test)\n",
        "print(\"GNB f1: \", gnb_f1_test)\n",
        "print('\\nGNB Classification Report:\\n' + classification_report(y_test, gnb_predictions)+'\\n')\n",
        "\n",
        "# Save the results for the optimization using F1 metric\n",
        "gnb_accuracy_F1 = gnb_acc_test\n",
        "gnb_f1_F1 = gnb_f1_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djs3Em4sOnOD"
      },
      "source": [
        "### K Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiERzkomZuf3"
      },
      "source": [
        "**Hyperparameter optimization with grid search (using Optuna)**\n",
        "\n",
        "Στη συνέχεια θα προσπαθήσουμε να βελτιστοποίησουμε τις υπερπαραμέτρους του ταξινομητή μας χρησιμοποιώντας τη βιβλιοθήκη Optuna. Μέσω αυτής θα κάνουμε GridSearch και CV σε 3 κύριες υπερπαραμέτρους του kNN Classifier, τον αριθμό n_neighbors, τα weights και τα metrics.\n",
        "Χρησιμοποιούμε ακόμα Pipelines για scaling και classification και δοκιμαζουμε τρεις διαφορετικούς scalers για να βρούμε τον καλύτερο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzY8If8wXfmb"
      },
      "source": [
        "**Βελτιστοποίηση βάσει του accuracy score.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "QHKikTAlgPcY"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Optimization using Optuna\n",
        "def kNN_objective(trial):\n",
        "\n",
        "  # Hyperparameters setting\n",
        "  scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust'])\n",
        "\n",
        "  if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "  elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "  else:\n",
        "        scaler = RobustScaler()\n",
        "        \n",
        "  n_neighbors = trial.suggest_int('n_neighbors', 1, 30)\n",
        "  weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
        "  metric = trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
        "  # leaf_size = trial.suggest_int('leaf_size', 1, 30)\n",
        "\n",
        "  # Pipeline Creation for data scaling and classification\n",
        "  kNN = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, \n",
        "                                       weights=weights, \n",
        "                                       metric=metric)\n",
        "  # Normalization + Model Creation\n",
        "  kNN_pipeline = make_pipeline(scaler, kNN)\n",
        "\n",
        "  # Model training with cv\n",
        "  score = cross_val_score(kNN_pipeline, x_train, y_train, scoring='accuracy', cv = 10, n_jobs = 1)\n",
        "  # score = score.mean()\n",
        "  return score.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq7VJxmytAhD",
        "outputId": "341feb80-3555-49f7-ce01-06a7f2b1e49a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-27 10:25:35,895]\u001b[0m A new study created in memory with name: no-name-3c6d0646-53fe-46d3-84d7-f0ba6dbc6286\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,930]\u001b[0m Trial 0 finished with value: 0.6709523809523811 and parameters: {'scalers': 'standard', 'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.6709523809523811.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:35,987]\u001b[0m Trial 1 finished with value: 0.5571428571428572 and parameters: {'scalers': 'robust', 'n_neighbors': 25, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.6709523809523811.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,039]\u001b[0m Trial 2 finished with value: 0.7623809523809524 and parameters: {'scalers': 'robust', 'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 2 with value: 0.7623809523809524.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,071]\u001b[0m Trial 3 finished with value: 0.6285714285714286 and parameters: {'scalers': 'standard', 'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 2 with value: 0.7623809523809524.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,126]\u001b[0m Trial 4 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 4 with value: 0.7976190476190476.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,154]\u001b[0m Trial 5 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,184]\u001b[0m Trial 6 finished with value: 0.7557142857142857 and parameters: {'scalers': 'standard', 'n_neighbors': 6, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,240]\u001b[0m Trial 7 finished with value: 0.7047619047619047 and parameters: {'scalers': 'robust', 'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,279]\u001b[0m Trial 8 finished with value: 0.6980952380952381 and parameters: {'scalers': 'standard', 'n_neighbors': 22, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,305]\u001b[0m Trial 9 finished with value: 0.7838095238095237 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,335]\u001b[0m Trial 10 finished with value: 0.7838095238095237 and parameters: {'scalers': 'minmax', 'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,365]\u001b[0m Trial 11 finished with value: 0.7914285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,423]\u001b[0m Trial 12 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8185714285714285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,462]\u001b[0m Trial 13 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,498]\u001b[0m Trial 14 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,535]\u001b[0m Trial 15 finished with value: 0.749047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 1, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,569]\u001b[0m Trial 16 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,604]\u001b[0m Trial 17 finished with value: 0.7838095238095237 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,636]\u001b[0m Trial 18 finished with value: 0.8119047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,669]\u001b[0m Trial 19 finished with value: 0.7838095238095237 and parameters: {'scalers': 'minmax', 'n_neighbors': 22, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,698]\u001b[0m Trial 20 finished with value: 0.8052380952380951 and parameters: {'scalers': 'minmax', 'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,729]\u001b[0m Trial 21 finished with value: 0.8185714285714287 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,760]\u001b[0m Trial 22 finished with value: 0.8185714285714287 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,796]\u001b[0m Trial 23 finished with value: 0.797142857142857 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,826]\u001b[0m Trial 24 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,858]\u001b[0m Trial 25 finished with value: 0.8185714285714287 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,892]\u001b[0m Trial 26 finished with value: 0.6904761904761905 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,923]\u001b[0m Trial 27 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,954]\u001b[0m Trial 28 finished with value: 0.7842857142857143 and parameters: {'scalers': 'minmax', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:36,991]\u001b[0m Trial 29 finished with value: 0.6695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,025]\u001b[0m Trial 30 finished with value: 0.7904761904761904 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,058]\u001b[0m Trial 31 finished with value: 0.8185714285714287 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,102]\u001b[0m Trial 32 finished with value: 0.8119047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,136]\u001b[0m Trial 33 finished with value: 0.8185714285714287 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,201]\u001b[0m Trial 34 finished with value: 0.5776190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 20, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,235]\u001b[0m Trial 35 finished with value: 0.7766666666666666 and parameters: {'scalers': 'minmax', 'n_neighbors': 24, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,271]\u001b[0m Trial 36 finished with value: 0.8119047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,332]\u001b[0m Trial 37 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,370]\u001b[0m Trial 38 finished with value: 0.6685714285714286 and parameters: {'scalers': 'standard', 'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,404]\u001b[0m Trial 39 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,438]\u001b[0m Trial 40 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,471]\u001b[0m Trial 41 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,503]\u001b[0m Trial 42 finished with value: 0.8114285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,534]\u001b[0m Trial 43 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,566]\u001b[0m Trial 44 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,623]\u001b[0m Trial 45 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,659]\u001b[0m Trial 46 finished with value: 0.6561904761904762 and parameters: {'scalers': 'minmax', 'n_neighbors': 21, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,702]\u001b[0m Trial 47 finished with value: 0.7914285714285714 and parameters: {'scalers': 'standard', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,736]\u001b[0m Trial 48 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,769]\u001b[0m Trial 49 finished with value: 0.8052380952380952 and parameters: {'scalers': 'minmax', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,828]\u001b[0m Trial 50 finished with value: 0.77 and parameters: {'scalers': 'robust', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,861]\u001b[0m Trial 51 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,892]\u001b[0m Trial 52 finished with value: 0.8114285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,924]\u001b[0m Trial 53 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,959]\u001b[0m Trial 54 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:37,989]\u001b[0m Trial 55 finished with value: 0.798095238095238 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,022]\u001b[0m Trial 56 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,055]\u001b[0m Trial 57 finished with value: 0.8052380952380952 and parameters: {'scalers': 'minmax', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,088]\u001b[0m Trial 58 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,123]\u001b[0m Trial 59 finished with value: 0.7628571428571428 and parameters: {'scalers': 'minmax', 'n_neighbors': 2, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,156]\u001b[0m Trial 60 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,191]\u001b[0m Trial 61 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,226]\u001b[0m Trial 62 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,260]\u001b[0m Trial 63 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,301]\u001b[0m Trial 64 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,334]\u001b[0m Trial 65 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,370]\u001b[0m Trial 66 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,402]\u001b[0m Trial 67 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,434]\u001b[0m Trial 68 finished with value: 0.797142857142857 and parameters: {'scalers': 'minmax', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,468]\u001b[0m Trial 69 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,501]\u001b[0m Trial 70 finished with value: 0.7833333333333334 and parameters: {'scalers': 'minmax', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,535]\u001b[0m Trial 71 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,569]\u001b[0m Trial 72 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,603]\u001b[0m Trial 73 finished with value: 0.7914285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,645]\u001b[0m Trial 74 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,703]\u001b[0m Trial 75 finished with value: 0.7695238095238095 and parameters: {'scalers': 'robust', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,737]\u001b[0m Trial 76 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,777]\u001b[0m Trial 77 finished with value: 0.7119047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,810]\u001b[0m Trial 78 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,844]\u001b[0m Trial 79 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,878]\u001b[0m Trial 80 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,911]\u001b[0m Trial 81 finished with value: 0.8052380952380952 and parameters: {'scalers': 'minmax', 'n_neighbors': 29, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,946]\u001b[0m Trial 82 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:38,981]\u001b[0m Trial 83 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,015]\u001b[0m Trial 84 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,048]\u001b[0m Trial 85 finished with value: 0.8114285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,082]\u001b[0m Trial 86 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,115]\u001b[0m Trial 87 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,150]\u001b[0m Trial 88 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,187]\u001b[0m Trial 89 finished with value: 0.719047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,259]\u001b[0m Trial 90 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,294]\u001b[0m Trial 91 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,335]\u001b[0m Trial 92 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,369]\u001b[0m Trial 93 finished with value: 0.8114285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,402]\u001b[0m Trial 94 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,436]\u001b[0m Trial 95 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,471]\u001b[0m Trial 96 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,506]\u001b[0m Trial 97 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,549]\u001b[0m Trial 98 finished with value: 0.7838095238095237 and parameters: {'scalers': 'standard', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,585]\u001b[0m Trial 99 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,626]\u001b[0m Trial 100 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,661]\u001b[0m Trial 101 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,697]\u001b[0m Trial 102 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,732]\u001b[0m Trial 103 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,767]\u001b[0m Trial 104 finished with value: 0.790952380952381 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,800]\u001b[0m Trial 105 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,836]\u001b[0m Trial 106 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,876]\u001b[0m Trial 107 finished with value: 0.6704761904761904 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,942]\u001b[0m Trial 108 finished with value: 0.798095238095238 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:39,978]\u001b[0m Trial 109 finished with value: 0.8047619047619048 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,013]\u001b[0m Trial 110 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,049]\u001b[0m Trial 111 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,083]\u001b[0m Trial 112 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,116]\u001b[0m Trial 113 finished with value: 0.7909523809523809 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,149]\u001b[0m Trial 114 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,183]\u001b[0m Trial 115 finished with value: 0.8185714285714285 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,216]\u001b[0m Trial 116 finished with value: 0.7914285714285714 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,251]\u001b[0m Trial 117 finished with value: 0.819047619047619 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 13 with value: 0.819047619047619.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,287]\u001b[0m Trial 118 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,323]\u001b[0m Trial 119 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,365]\u001b[0m Trial 120 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,401]\u001b[0m Trial 121 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,438]\u001b[0m Trial 122 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,478]\u001b[0m Trial 123 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,516]\u001b[0m Trial 124 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,552]\u001b[0m Trial 125 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 118 with value: 0.832857142857143.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,588]\u001b[0m Trial 126 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,627]\u001b[0m Trial 127 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,666]\u001b[0m Trial 128 finished with value: 0.6785714285714285 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,702]\u001b[0m Trial 129 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,744]\u001b[0m Trial 130 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,779]\u001b[0m Trial 131 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,815]\u001b[0m Trial 132 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,851]\u001b[0m Trial 133 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,888]\u001b[0m Trial 134 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,925]\u001b[0m Trial 135 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,963]\u001b[0m Trial 136 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:40,999]\u001b[0m Trial 137 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,033]\u001b[0m Trial 138 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,071]\u001b[0m Trial 139 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,107]\u001b[0m Trial 140 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,143]\u001b[0m Trial 141 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,179]\u001b[0m Trial 142 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,215]\u001b[0m Trial 143 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,251]\u001b[0m Trial 144 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,287]\u001b[0m Trial 145 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,323]\u001b[0m Trial 146 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,369]\u001b[0m Trial 147 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,405]\u001b[0m Trial 148 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,442]\u001b[0m Trial 149 finished with value: 0.811904761904762 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,479]\u001b[0m Trial 150 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,516]\u001b[0m Trial 151 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,555]\u001b[0m Trial 152 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,593]\u001b[0m Trial 153 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,631]\u001b[0m Trial 154 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,668]\u001b[0m Trial 155 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,704]\u001b[0m Trial 156 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,745]\u001b[0m Trial 157 finished with value: 0.7061904761904761 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,784]\u001b[0m Trial 158 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,820]\u001b[0m Trial 159 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,856]\u001b[0m Trial 160 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,893]\u001b[0m Trial 161 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,930]\u001b[0m Trial 162 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:41,971]\u001b[0m Trial 163 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,013]\u001b[0m Trial 164 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,049]\u001b[0m Trial 165 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,085]\u001b[0m Trial 166 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,122]\u001b[0m Trial 167 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,160]\u001b[0m Trial 168 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,201]\u001b[0m Trial 169 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,240]\u001b[0m Trial 170 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,277]\u001b[0m Trial 171 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,315]\u001b[0m Trial 172 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,352]\u001b[0m Trial 173 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,398]\u001b[0m Trial 174 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,435]\u001b[0m Trial 175 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,478]\u001b[0m Trial 176 finished with value: 0.8047619047619048 and parameters: {'scalers': 'standard', 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,514]\u001b[0m Trial 177 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,554]\u001b[0m Trial 178 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,599]\u001b[0m Trial 179 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,638]\u001b[0m Trial 180 finished with value: 0.811904761904762 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,676]\u001b[0m Trial 181 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,714]\u001b[0m Trial 182 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,751]\u001b[0m Trial 183 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,788]\u001b[0m Trial 184 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,826]\u001b[0m Trial 185 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,864]\u001b[0m Trial 186 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,903]\u001b[0m Trial 187 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,941]\u001b[0m Trial 188 finished with value: 0.7061904761904761 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:42,977]\u001b[0m Trial 189 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,013]\u001b[0m Trial 190 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,049]\u001b[0m Trial 191 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,087]\u001b[0m Trial 192 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,126]\u001b[0m Trial 193 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,164]\u001b[0m Trial 194 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,203]\u001b[0m Trial 195 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,246]\u001b[0m Trial 196 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,286]\u001b[0m Trial 197 finished with value: 0.7904761904761904 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,322]\u001b[0m Trial 198 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,358]\u001b[0m Trial 199 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,402]\u001b[0m Trial 200 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,440]\u001b[0m Trial 201 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,480]\u001b[0m Trial 202 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,517]\u001b[0m Trial 203 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,555]\u001b[0m Trial 204 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,592]\u001b[0m Trial 205 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,654]\u001b[0m Trial 206 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,691]\u001b[0m Trial 207 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,731]\u001b[0m Trial 208 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,768]\u001b[0m Trial 209 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,805]\u001b[0m Trial 210 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,857]\u001b[0m Trial 211 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,896]\u001b[0m Trial 212 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,933]\u001b[0m Trial 213 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:43,973]\u001b[0m Trial 214 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,010]\u001b[0m Trial 215 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,048]\u001b[0m Trial 216 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,089]\u001b[0m Trial 217 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,127]\u001b[0m Trial 218 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,168]\u001b[0m Trial 219 finished with value: 0.6995238095238094 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,207]\u001b[0m Trial 220 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,245]\u001b[0m Trial 221 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,282]\u001b[0m Trial 222 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,320]\u001b[0m Trial 223 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,357]\u001b[0m Trial 224 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,395]\u001b[0m Trial 225 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,447]\u001b[0m Trial 226 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,487]\u001b[0m Trial 227 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,528]\u001b[0m Trial 228 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,568]\u001b[0m Trial 229 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,607]\u001b[0m Trial 230 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,645]\u001b[0m Trial 231 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,684]\u001b[0m Trial 232 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,722]\u001b[0m Trial 233 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,764]\u001b[0m Trial 234 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,801]\u001b[0m Trial 235 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,841]\u001b[0m Trial 236 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,904]\u001b[0m Trial 237 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,942]\u001b[0m Trial 238 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:44,980]\u001b[0m Trial 239 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,019]\u001b[0m Trial 240 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,068]\u001b[0m Trial 241 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,109]\u001b[0m Trial 242 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,150]\u001b[0m Trial 243 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,190]\u001b[0m Trial 244 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,231]\u001b[0m Trial 245 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,270]\u001b[0m Trial 246 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,308]\u001b[0m Trial 247 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,347]\u001b[0m Trial 248 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,386]\u001b[0m Trial 249 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,427]\u001b[0m Trial 250 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,474]\u001b[0m Trial 251 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,512]\u001b[0m Trial 252 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,555]\u001b[0m Trial 253 finished with value: 0.7061904761904761 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,593]\u001b[0m Trial 254 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,631]\u001b[0m Trial 255 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,676]\u001b[0m Trial 256 finished with value: 0.8119047619047617 and parameters: {'scalers': 'standard', 'n_neighbors': 25, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,715]\u001b[0m Trial 257 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,754]\u001b[0m Trial 258 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,792]\u001b[0m Trial 259 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,830]\u001b[0m Trial 260 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,869]\u001b[0m Trial 261 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,937]\u001b[0m Trial 262 finished with value: 0.77 and parameters: {'scalers': 'robust', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:45,977]\u001b[0m Trial 263 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,015]\u001b[0m Trial 264 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,057]\u001b[0m Trial 265 finished with value: 0.804285714285714 and parameters: {'scalers': 'standard', 'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,095]\u001b[0m Trial 266 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,135]\u001b[0m Trial 267 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,177]\u001b[0m Trial 268 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,218]\u001b[0m Trial 269 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,258]\u001b[0m Trial 270 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,297]\u001b[0m Trial 271 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,340]\u001b[0m Trial 272 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,385]\u001b[0m Trial 273 finished with value: 0.7057142857142857 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,423]\u001b[0m Trial 274 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,469]\u001b[0m Trial 275 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,509]\u001b[0m Trial 276 finished with value: 0.8257142857142856 and parameters: {'scalers': 'standard', 'n_neighbors': 29, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,549]\u001b[0m Trial 277 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,590]\u001b[0m Trial 278 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,629]\u001b[0m Trial 279 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,667]\u001b[0m Trial 280 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,708]\u001b[0m Trial 281 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,752]\u001b[0m Trial 282 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,796]\u001b[0m Trial 283 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,840]\u001b[0m Trial 284 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,907]\u001b[0m Trial 285 finished with value: 0.798095238095238 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,949]\u001b[0m Trial 286 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:46,989]\u001b[0m Trial 287 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,030]\u001b[0m Trial 288 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,072]\u001b[0m Trial 289 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,112]\u001b[0m Trial 290 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,152]\u001b[0m Trial 291 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,194]\u001b[0m Trial 292 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,236]\u001b[0m Trial 293 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,280]\u001b[0m Trial 294 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,324]\u001b[0m Trial 295 finished with value: 0.7838095238095237 and parameters: {'scalers': 'standard', 'n_neighbors': 1, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,364]\u001b[0m Trial 296 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,405]\u001b[0m Trial 297 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,445]\u001b[0m Trial 298 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,499]\u001b[0m Trial 299 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,539]\u001b[0m Trial 300 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,579]\u001b[0m Trial 301 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,617]\u001b[0m Trial 302 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,657]\u001b[0m Trial 303 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,700]\u001b[0m Trial 304 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,740]\u001b[0m Trial 305 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,803]\u001b[0m Trial 306 finished with value: 0.7628571428571429 and parameters: {'scalers': 'robust', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,842]\u001b[0m Trial 307 finished with value: 0.798095238095238 and parameters: {'scalers': 'standard', 'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,883]\u001b[0m Trial 308 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,924]\u001b[0m Trial 309 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:47,967]\u001b[0m Trial 310 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,007]\u001b[0m Trial 311 finished with value: 0.8047619047619048 and parameters: {'scalers': 'standard', 'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,050]\u001b[0m Trial 312 finished with value: 0.7061904761904761 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,092]\u001b[0m Trial 313 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,132]\u001b[0m Trial 314 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,172]\u001b[0m Trial 315 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,214]\u001b[0m Trial 316 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,261]\u001b[0m Trial 317 finished with value: 0.811904761904762 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,305]\u001b[0m Trial 318 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,345]\u001b[0m Trial 319 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,385]\u001b[0m Trial 320 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,424]\u001b[0m Trial 321 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,466]\u001b[0m Trial 322 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,515]\u001b[0m Trial 323 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,557]\u001b[0m Trial 324 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,597]\u001b[0m Trial 325 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,638]\u001b[0m Trial 326 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,710]\u001b[0m Trial 327 finished with value: 0.798095238095238 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,751]\u001b[0m Trial 328 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,793]\u001b[0m Trial 329 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,838]\u001b[0m Trial 330 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,879]\u001b[0m Trial 331 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,924]\u001b[0m Trial 332 finished with value: 0.6847619047619048 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:48,969]\u001b[0m Trial 333 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,013]\u001b[0m Trial 334 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,055]\u001b[0m Trial 335 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,097]\u001b[0m Trial 336 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,140]\u001b[0m Trial 337 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,181]\u001b[0m Trial 338 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,225]\u001b[0m Trial 339 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,266]\u001b[0m Trial 340 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,306]\u001b[0m Trial 341 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,347]\u001b[0m Trial 342 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,388]\u001b[0m Trial 343 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,429]\u001b[0m Trial 344 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,470]\u001b[0m Trial 345 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,512]\u001b[0m Trial 346 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,561]\u001b[0m Trial 347 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,616]\u001b[0m Trial 348 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,681]\u001b[0m Trial 349 finished with value: 0.8047619047619048 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,723]\u001b[0m Trial 350 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,769]\u001b[0m Trial 351 finished with value: 0.6919047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,810]\u001b[0m Trial 352 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,853]\u001b[0m Trial 353 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,895]\u001b[0m Trial 354 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,939]\u001b[0m Trial 355 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:49,981]\u001b[0m Trial 356 finished with value: 0.7904761904761904 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,022]\u001b[0m Trial 357 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,064]\u001b[0m Trial 358 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,106]\u001b[0m Trial 359 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,148]\u001b[0m Trial 360 finished with value: 0.819047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 27, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,192]\u001b[0m Trial 361 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,234]\u001b[0m Trial 362 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,275]\u001b[0m Trial 363 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,317]\u001b[0m Trial 364 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,360]\u001b[0m Trial 365 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,401]\u001b[0m Trial 366 finished with value: 0.8114285714285714 and parameters: {'scalers': 'standard', 'n_neighbors': 23, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,443]\u001b[0m Trial 367 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,484]\u001b[0m Trial 368 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,532]\u001b[0m Trial 369 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,611]\u001b[0m Trial 370 finished with value: 0.6057142857142856 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,654]\u001b[0m Trial 371 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,696]\u001b[0m Trial 372 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,742]\u001b[0m Trial 373 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,784]\u001b[0m Trial 374 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,826]\u001b[0m Trial 375 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,869]\u001b[0m Trial 376 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,912]\u001b[0m Trial 377 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:50,959]\u001b[0m Trial 378 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,001]\u001b[0m Trial 379 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,044]\u001b[0m Trial 380 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,088]\u001b[0m Trial 381 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,131]\u001b[0m Trial 382 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,174]\u001b[0m Trial 383 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,217]\u001b[0m Trial 384 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,260]\u001b[0m Trial 385 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,303]\u001b[0m Trial 386 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,348]\u001b[0m Trial 387 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,391]\u001b[0m Trial 388 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,434]\u001b[0m Trial 389 finished with value: 0.811904761904762 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,479]\u001b[0m Trial 390 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,555]\u001b[0m Trial 391 finished with value: 0.5723809523809523 and parameters: {'scalers': 'robust', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,606]\u001b[0m Trial 392 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,648]\u001b[0m Trial 393 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,691]\u001b[0m Trial 394 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,742]\u001b[0m Trial 395 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,785]\u001b[0m Trial 396 finished with value: 0.7904761904761904 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,833]\u001b[0m Trial 397 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,877]\u001b[0m Trial 398 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,921]\u001b[0m Trial 399 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:51,966]\u001b[0m Trial 400 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,011]\u001b[0m Trial 401 finished with value: 0.7628571428571429 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,054]\u001b[0m Trial 402 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,096]\u001b[0m Trial 403 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,140]\u001b[0m Trial 404 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,182]\u001b[0m Trial 405 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,226]\u001b[0m Trial 406 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,271]\u001b[0m Trial 407 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,313]\u001b[0m Trial 408 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,357]\u001b[0m Trial 409 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,400]\u001b[0m Trial 410 finished with value: 0.8047619047619048 and parameters: {'scalers': 'standard', 'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,443]\u001b[0m Trial 411 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,487]\u001b[0m Trial 412 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,558]\u001b[0m Trial 413 finished with value: 0.6352380952380952 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,609]\u001b[0m Trial 414 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,663]\u001b[0m Trial 415 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,708]\u001b[0m Trial 416 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,752]\u001b[0m Trial 417 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,797]\u001b[0m Trial 418 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,841]\u001b[0m Trial 419 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,886]\u001b[0m Trial 420 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,935]\u001b[0m Trial 421 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:52,980]\u001b[0m Trial 422 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,021]\u001b[0m Trial 423 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,065]\u001b[0m Trial 424 finished with value: 0.7904761904761904 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,108]\u001b[0m Trial 425 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,152]\u001b[0m Trial 426 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,195]\u001b[0m Trial 427 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,239]\u001b[0m Trial 428 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,287]\u001b[0m Trial 429 finished with value: 0.6995238095238094 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,331]\u001b[0m Trial 430 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,375]\u001b[0m Trial 431 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,420]\u001b[0m Trial 432 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,467]\u001b[0m Trial 433 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,511]\u001b[0m Trial 434 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,588]\u001b[0m Trial 435 finished with value: 0.7976190476190476 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,646]\u001b[0m Trial 436 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,698]\u001b[0m Trial 437 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,750]\u001b[0m Trial 438 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,796]\u001b[0m Trial 439 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,844]\u001b[0m Trial 440 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,890]\u001b[0m Trial 441 finished with value: 0.7976190476190476 and parameters: {'scalers': 'standard', 'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,938]\u001b[0m Trial 442 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:53,982]\u001b[0m Trial 443 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,025]\u001b[0m Trial 444 finished with value: 0.7628571428571429 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,069]\u001b[0m Trial 445 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,115]\u001b[0m Trial 446 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,159]\u001b[0m Trial 447 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,204]\u001b[0m Trial 448 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,249]\u001b[0m Trial 449 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,297]\u001b[0m Trial 450 finished with value: 0.7061904761904761 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,343]\u001b[0m Trial 451 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,388]\u001b[0m Trial 452 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,434]\u001b[0m Trial 453 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,488]\u001b[0m Trial 454 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,535]\u001b[0m Trial 455 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,603]\u001b[0m Trial 456 finished with value: 0.7557142857142858 and parameters: {'scalers': 'robust', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,654]\u001b[0m Trial 457 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,698]\u001b[0m Trial 458 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,744]\u001b[0m Trial 459 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,788]\u001b[0m Trial 460 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,832]\u001b[0m Trial 461 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,877]\u001b[0m Trial 462 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,922]\u001b[0m Trial 463 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:54,974]\u001b[0m Trial 464 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,019]\u001b[0m Trial 465 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,066]\u001b[0m Trial 466 finished with value: 0.6995238095238094 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,112]\u001b[0m Trial 467 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,155]\u001b[0m Trial 468 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,199]\u001b[0m Trial 469 finished with value: 0.7766666666666666 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,245]\u001b[0m Trial 470 finished with value: 0.8123809523809523 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,288]\u001b[0m Trial 471 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,333]\u001b[0m Trial 472 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,378]\u001b[0m Trial 473 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,424]\u001b[0m Trial 474 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,470]\u001b[0m Trial 475 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,515]\u001b[0m Trial 476 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,564]\u001b[0m Trial 477 finished with value: 0.8047619047619048 and parameters: {'scalers': 'standard', 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,634]\u001b[0m Trial 478 finished with value: 0.8047619047619048 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,690]\u001b[0m Trial 479 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,750]\u001b[0m Trial 480 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,796]\u001b[0m Trial 481 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,842]\u001b[0m Trial 482 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,903]\u001b[0m Trial 483 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,951]\u001b[0m Trial 484 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:55,999]\u001b[0m Trial 485 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,045]\u001b[0m Trial 486 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,094]\u001b[0m Trial 487 finished with value: 0.6857142857142857 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,140]\u001b[0m Trial 488 finished with value: 0.7695238095238095 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,186]\u001b[0m Trial 489 finished with value: 0.7628571428571429 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,231]\u001b[0m Trial 490 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,277]\u001b[0m Trial 491 finished with value: 0.832857142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,324]\u001b[0m Trial 492 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,370]\u001b[0m Trial 493 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,416]\u001b[0m Trial 494 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,467]\u001b[0m Trial 495 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,514]\u001b[0m Trial 496 finished with value: 0.8119047619047619 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,563]\u001b[0m Trial 497 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,618]\u001b[0m Trial 498 finished with value: 0.8333333333333334 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:56,694]\u001b[0m Trial 499 finished with value: 0.8047619047619048 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 126 with value: 0.8333333333333334.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "kNN_sampler = TPESampler(seed=42) # create a seed for the sampler for reproducibility\n",
        "kNN_study = optuna.create_study(direction=\"maximize\", sampler=kNN_sampler)\n",
        "kNN_study.optimize(kNN_objective, n_trials=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Ic12PVeO2bRb",
        "outputId": "aaba2378-e6c8-46ec-ea49-44db24fd1731"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"15626a51-eb70-4dfe-960e-61afec2c94fa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"15626a51-eb70-4dfe-960e-61afec2c94fa\")) {                    Plotly.newPlot(                        \"15626a51-eb70-4dfe-960e-61afec2c94fa\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.6709523809523811,0.5571428571428572,0.7623809523809524,0.6285714285714286,0.7976190476190476,0.8185714285714285,0.7557142857142857,0.7047619047619047,0.6980952380952381,0.7838095238095237,0.7838095238095237,0.7914285714285714,0.7976190476190476,0.819047619047619,0.8047619047619048,0.749047619047619,0.8047619047619048,0.7838095238095237,0.8119047619047619,0.7838095238095237,0.8052380952380951,0.8185714285714287,0.8185714285714287,0.797142857142857,0.7909523809523809,0.8185714285714287,0.6904761904761905,0.8047619047619048,0.7842857142857143,0.6695238095238095,0.7904761904761904,0.8185714285714287,0.8119047619047619,0.8185714285714287,0.5776190476190476,0.7766666666666666,0.8119047619047619,0.7976190476190476,0.6685714285714286,0.7909523809523809,0.819047619047619,0.819047619047619,0.8114285714285714,0.819047619047619,0.790952380952381,0.7976190476190476,0.6561904761904762,0.7914285714285714,0.790952380952381,0.8052380952380952,0.77,0.819047619047619,0.8114285714285714,0.819047619047619,0.7909523809523809,0.798095238095238,0.8185714285714285,0.8052380952380952,0.8047619047619048,0.7628571428571428,0.819047619047619,0.819047619047619,0.819047619047619,0.790952380952381,0.819047619047619,0.8185714285714285,0.8119047619047619,0.819047619047619,0.797142857142857,0.819047619047619,0.7833333333333334,0.790952380952381,0.819047619047619,0.7914285714285714,0.7909523809523809,0.7695238095238095,0.819047619047619,0.7119047619047619,0.8185714285714285,0.8119047619047619,0.819047619047619,0.8052380952380952,0.8047619047619048,0.7909523809523809,0.819047619047619,0.8114285714285714,0.819047619047619,0.819047619047619,0.8185714285714285,0.719047619047619,0.7976190476190476,0.819047619047619,0.790952380952381,0.8114285714285714,0.819047619047619,0.819047619047619,0.819047619047619,0.8185714285714285,0.7838095238095237,0.7909523809523809,0.7909523809523809,0.819047619047619,0.819047619047619,0.819047619047619,0.790952380952381,0.819047619047619,0.7909523809523809,0.6704761904761904,0.798095238095238,0.8047619047619048,0.819047619047619,0.819047619047619,0.819047619047619,0.7909523809523809,0.8185714285714285,0.8185714285714285,0.7914285714285714,0.819047619047619,0.832857142857143,0.8119047619047619,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.8333333333333334,0.8333333333333334,0.6785714285714285,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.7766666666666666,0.8333333333333334,0.8123809523809523,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8123809523809523,0.8119047619047619,0.811904761904762,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.7061904761904761,0.7766666666666666,0.8123809523809523,0.7695238095238095,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8123809523809523,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8047619047619048,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.811904761904762,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8123809523809523,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.7061904761904761,0.7695238095238095,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8123809523809523,0.7904761904761904,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7976190476190476,0.8119047619047619,0.8119047619047619,0.832857142857143,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8123809523809523,0.8119047619047619,0.6995238095238094,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.7695238095238095,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.832857142857143,0.7976190476190476,0.8333333333333334,0.8123809523809523,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7061904761904761,0.8119047619047619,0.8333333333333334,0.8119047619047617,0.832857142857143,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.7766666666666666,0.77,0.7695238095238095,0.8119047619047619,0.804285714285714,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.832857142857143,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.7057142857142857,0.8333333333333334,0.8123809523809523,0.8257142857142856,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7766666666666666,0.798095238095238,0.8119047619047619,0.8123809523809523,0.7695238095238095,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.7838095238095237,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.832857142857143,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.7628571428571429,0.798095238095238,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8047619047619048,0.7061904761904761,0.7766666666666666,0.8119047619047619,0.8119047619047619,0.832857142857143,0.811904761904762,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8123809523809523,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.798095238095238,0.8119047619047619,0.8119047619047619,0.7695238095238095,0.8333333333333334,0.6847619047619048,0.8123809523809523,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.832857142857143,0.8119047619047619,0.8333333333333334,0.8123809523809523,0.8333333333333334,0.8047619047619048,0.8333333333333334,0.6919047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.7904761904761904,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.819047619047619,0.8119047619047619,0.8333333333333334,0.8123809523809523,0.8119047619047619,0.8119047619047619,0.8114285714285714,0.8333333333333334,0.832857142857143,0.8119047619047619,0.6057142857142856,0.8333333333333334,0.8123809523809523,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.7695238095238095,0.8119047619047619,0.7766666666666666,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.832857142857143,0.8123809523809523,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.811904761904762,0.8333333333333334,0.5723809523809523,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.7904761904761904,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.7628571428571429,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.832857142857143,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8047619047619048,0.8119047619047619,0.8333333333333334,0.6352380952380952,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7695238095238095,0.8333333333333334,0.8119047619047619,0.8123809523809523,0.8119047619047619,0.8333333333333334,0.7904761904761904,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8123809523809523,0.6995238095238094,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7976190476190476,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.832857142857143,0.7976190476190476,0.8119047619047619,0.8333333333333334,0.7628571428571429,0.8333333333333334,0.7695238095238095,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.7061904761904761,0.8119047619047619,0.8333333333333334,0.832857142857143,0.8333333333333334,0.8119047619047619,0.7557142857142858,0.8119047619047619,0.8333333333333334,0.832857142857143,0.8119047619047619,0.8123809523809523,0.8333333333333334,0.7695238095238095,0.8119047619047619,0.8333333333333334,0.6995238095238094,0.8333333333333334,0.8119047619047619,0.7766666666666666,0.8123809523809523,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.832857142857143,0.8119047619047619,0.8047619047619048,0.8047619047619048,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.6857142857142857,0.7695238095238095,0.7628571428571429,0.8119047619047619,0.832857142857143,0.8333333333333334,0.8119047619047619,0.8333333333333334,0.8119047619047619,0.8119047619047619,0.8333333333333334,0.8333333333333334,0.8047619047619048],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.6709523809523811,0.6709523809523811,0.7623809523809524,0.7623809523809524,0.7976190476190476,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.8185714285714285,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.819047619047619,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.832857142857143,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('15626a51-eb70-4dfe-960e-61afec2c94fa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(kNN_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pfcjOD_H1-uJ",
        "outputId": "967feeee-e3c0-410f-9464-4f6703767e8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d3c61cea-0b60-4837-96b4-7178ec623101\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d3c61cea-0b60-4837-96b4-7178ec623101\")) {                    Plotly.newPlot(                        \"d3c61cea-0b60-4837-96b4-7178ec623101\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"metric (CategoricalDistribution): 0.02057556696210186<extra></extra>\",\"n_neighbors (IntDistribution): 0.043474782500744304<extra></extra>\",\"scalers (CategoricalDistribution): 0.06728477802206473<extra></extra>\",\"weights (CategoricalDistribution): 0.8686648725150892<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02\",\"0.04\",\"0.07\",\"0.87\"],\"textposition\":\"outside\",\"x\":[0.02057556696210186,0.043474782500744304,0.06728477802206473,0.8686648725150892],\"y\":[\"metric\",\"n_neighbors\",\"scalers\",\"weights\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d3c61cea-0b60-4837-96b4-7178ec623101');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_param_importances(kNN_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBECKDrTPnTy"
      },
      "source": [
        "Διαπιστώνουμε ότι οι παρακάτω παράμετροι είναι οι βέλτιστες στο training set όταν εκπαιδεύουμε βάσει του accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erD38Si02Fe1",
        "outputId": "91bceba2-50c6-43dc-85e6-a6273f36ce7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters after tuning using mean accuracy:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'scalers': 'standard',\n",
              " 'n_neighbors': 11,\n",
              " 'weights': 'distance',\n",
              " 'metric': 'manhattan'}"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Best parameters after tuning using mean accuracy:\")\n",
        "kNN_study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZIWazwcP0Sn"
      },
      "source": [
        "Θα χρησιμοποιήσουμε στη συνέχεια τις παραπάνω παραμέτρους για να υπολογίσουμε τα accuracy και f1-macro στο test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HdzAI49ND1",
        "outputId": "aa0747bf-f95b-4a03-97a9-da64b47da2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος train και test: 0.0587766170501709 seconds\n",
            "Training Set:\n",
            "kNN accuracy:  0.8333333333333334\n",
            "kNN f1:  0.832293956043956\n",
            "\n",
            "Testing set:\n",
            "kNN accuracy:  0.92\n",
            "kNN f1 macro:  0.9178981937602627\n",
            "\n",
            "kNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.90      0.90        21\n",
            "         1.0       0.93      0.93      0.93        29\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.92      0.92      0.92        50\n",
            "weighted avg       0.92      0.92      0.92        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "best_params = kNN_study.best_params\n",
        "\n",
        "if best_params['scalers'] == \"minmax\":\n",
        "  opt_scaler = MinMaxScaler()\n",
        "elif best_params['scalers'] == \"standard\":\n",
        "  opt_scaler = StandardScaler()\n",
        "else:\n",
        "  opt_scaler = RobustScaler()\n",
        "\n",
        "del best_params['scalers']\n",
        "\n",
        "# Creation of knn classifier with optimized parameters\n",
        "kNN_clf_opt = neighbors.KNeighborsClassifier(**best_params)\n",
        "kNN_pipeline = make_pipeline(opt_scaler, kNN_clf_opt)\n",
        "\n",
        "# Kαταγραφή χρόνου train και test\n",
        "start_time = time.time()\n",
        "\n",
        "# Model training \n",
        "strtfdKFold = StratifiedKFold(n_splits=10)\n",
        "kNN_pipeline.fit(x_train, y_train)\n",
        "kNN_scores_acc = cross_val_score(kNN_pipeline, x_train, y_train, scoring='accuracy' ,cv = strtfdKFold, n_jobs=1)\n",
        "kNN_f1_macro_acc = cross_val_score(kNN_pipeline, x_train, y_train, scoring='f1_macro', cv = strtfdKFold, n_jobs=1)\n",
        "\n",
        "# Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(\"kNN accuracy: \", kNN_scores_acc.mean())\n",
        "print(\"kNN f1: \", kNN_f1_macro_acc.mean())\n",
        "\n",
        "kNN_acc_acc = kNN_pipeline.score(x_test, y_test)\n",
        "kNN_preds_acc = kNN_pipeline.predict(x_test)\n",
        "knn_f1_acc = f1_score(y_test, kNN_preds_acc, average='macro')\n",
        "\n",
        "print(\"\\nTesting set:\")\n",
        "print(\"kNN accuracy: \", kNN_acc_acc)\n",
        "print(\"kNN f1 macro: \", knn_f1_acc)\n",
        "print('\\nkNN Classification Report:\\n' + classification_report(y_test, kNN_preds_acc)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z61GzShKzBdZ"
      },
      "source": [
        "**Βελτιστοποίηση βάσει του f1-macro score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "GfhZbG2WhTq5"
      },
      "outputs": [],
      "source": [
        "def kNN_objective(trial):\n",
        "\n",
        "  #Hyperparameters setting\n",
        "  scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust'])\n",
        "\n",
        "  if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "  elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "  else:\n",
        "        scaler = RobustScaler()\n",
        "\n",
        "  n_neighbors = trial.suggest_int('n_neighbors', 1, 30)\n",
        "  weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
        "  metric = trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
        "  # leaf_size = trial.suggest_int('leaf_size', 1, 30)\n",
        "\n",
        "  #Pipeline Creation for data scaling and classification\n",
        "  knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, \n",
        "                                       weights=weights, \n",
        "                                       metric=metric)\n",
        "  # Normalization + Model Creation\n",
        "  pipeline = make_pipeline(scaler, knn)\n",
        "\n",
        "  #Model training with cv\n",
        "  score = cross_val_score(pipeline, x_train, y_train, scoring='f1_macro', cv=10, n_jobs=1)\n",
        "  score = score.mean()\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjOjF8FgzHNS",
        "outputId": "f546116e-32b2-41c6-9077-f2485e05dbdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-27 10:25:58,517]\u001b[0m A new study created in memory with name: no-name-9e3daeb0-9ea1-4c01-8ecb-58381a2694d2\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,560]\u001b[0m Trial 0 finished with value: 0.660348255975191 and parameters: {'scalers': 'standard', 'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.660348255975191.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,634]\u001b[0m Trial 1 finished with value: 0.524051807325801 and parameters: {'scalers': 'robust', 'n_neighbors': 25, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.660348255975191.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,692]\u001b[0m Trial 2 finished with value: 0.7557441904500728 and parameters: {'scalers': 'robust', 'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 2 with value: 0.7557441904500728.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,736]\u001b[0m Trial 3 finished with value: 0.6150520652378237 and parameters: {'scalers': 'standard', 'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 2 with value: 0.7557441904500728.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,795]\u001b[0m Trial 4 finished with value: 0.7879598600573832 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 4 with value: 0.7879598600573832.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,827]\u001b[0m Trial 5 finished with value: 0.8163596207713855 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,862]\u001b[0m Trial 6 finished with value: 0.7518192918192919 and parameters: {'scalers': 'standard', 'n_neighbors': 6, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,933]\u001b[0m Trial 7 finished with value: 0.7032097069597069 and parameters: {'scalers': 'robust', 'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:58,979]\u001b[0m Trial 8 finished with value: 0.6912083259877376 and parameters: {'scalers': 'standard', 'n_neighbors': 22, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,018]\u001b[0m Trial 9 finished with value: 0.7788958916900094 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,065]\u001b[0m Trial 10 finished with value: 0.7793303755068461 and parameters: {'scalers': 'minmax', 'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,108]\u001b[0m Trial 11 finished with value: 0.7885749054866702 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,151]\u001b[0m Trial 12 finished with value: 0.7864117826617827 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,192]\u001b[0m Trial 13 finished with value: 0.7788958916900094 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,233]\u001b[0m Trial 14 finished with value: 0.7984205023562608 and parameters: {'scalers': 'minmax', 'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,275]\u001b[0m Trial 15 finished with value: 0.785785684903332 and parameters: {'scalers': 'minmax', 'n_neighbors': 30, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,315]\u001b[0m Trial 16 finished with value: 0.7984205023562608 and parameters: {'scalers': 'minmax', 'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,355]\u001b[0m Trial 17 finished with value: 0.7606758192787605 and parameters: {'scalers': 'minmax', 'n_neighbors': 1, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,396]\u001b[0m Trial 18 finished with value: 0.8022836966954614 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,435]\u001b[0m Trial 19 finished with value: 0.8093899238016885 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,477]\u001b[0m Trial 20 finished with value: 0.7791485720162191 and parameters: {'scalers': 'minmax', 'n_neighbors': 22, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,521]\u001b[0m Trial 21 finished with value: 0.8022836966954614 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,565]\u001b[0m Trial 22 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,605]\u001b[0m Trial 23 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,644]\u001b[0m Trial 24 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,682]\u001b[0m Trial 25 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,731]\u001b[0m Trial 26 finished with value: 0.6668712986360045 and parameters: {'scalers': 'minmax', 'n_neighbors': 22, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,774]\u001b[0m Trial 27 finished with value: 0.7853783063341887 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,814]\u001b[0m Trial 28 finished with value: 0.795145418307183 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,883]\u001b[0m Trial 29 finished with value: 0.5537839611369023 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,925]\u001b[0m Trial 30 finished with value: 0.7939274695892342 and parameters: {'scalers': 'standard', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:25:59,966]\u001b[0m Trial 31 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,005]\u001b[0m Trial 32 finished with value: 0.7797521187962364 and parameters: {'scalers': 'minmax', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,045]\u001b[0m Trial 33 finished with value: 0.8017617186734833 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,113]\u001b[0m Trial 34 finished with value: 0.5976643862673274 and parameters: {'scalers': 'robust', 'n_neighbors': 14, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,152]\u001b[0m Trial 35 finished with value: 0.7932670270905565 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,191]\u001b[0m Trial 36 finished with value: 0.8017617186734833 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,254]\u001b[0m Trial 37 finished with value: 0.7819806663924311 and parameters: {'scalers': 'robust', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,298]\u001b[0m Trial 38 finished with value: 0.6513252528345408 and parameters: {'scalers': 'standard', 'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,337]\u001b[0m Trial 39 finished with value: 0.7793303755068461 and parameters: {'scalers': 'minmax', 'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,405]\u001b[0m Trial 40 finished with value: 0.5754850962590901 and parameters: {'scalers': 'robust', 'n_neighbors': 16, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,446]\u001b[0m Trial 41 finished with value: 0.7932670270905565 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,484]\u001b[0m Trial 42 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,523]\u001b[0m Trial 43 finished with value: 0.7797521187962364 and parameters: {'scalers': 'minmax', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,564]\u001b[0m Trial 44 finished with value: 0.8017617186734833 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,602]\u001b[0m Trial 45 finished with value: 0.7864117826617827 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,642]\u001b[0m Trial 46 finished with value: 0.7939274695892342 and parameters: {'scalers': 'standard', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,681]\u001b[0m Trial 47 finished with value: 0.8023824786324786 and parameters: {'scalers': 'minmax', 'n_neighbors': 23, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,718]\u001b[0m Trial 48 finished with value: 0.7932670270905565 and parameters: {'scalers': 'minmax', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 5 with value: 0.8163596207713855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,768]\u001b[0m Trial 49 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,808]\u001b[0m Trial 50 finished with value: 0.8019154456654455 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,847]\u001b[0m Trial 51 finished with value: 0.8168910256410257 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,885]\u001b[0m Trial 52 finished with value: 0.8089557746175394 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,922]\u001b[0m Trial 53 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:00,962]\u001b[0m Trial 54 finished with value: 0.7864117826617827 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,001]\u001b[0m Trial 55 finished with value: 0.7885749054866702 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,040]\u001b[0m Trial 56 finished with value: 0.8163596207713855 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,079]\u001b[0m Trial 57 finished with value: 0.7875507907125554 and parameters: {'scalers': 'minmax', 'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,117]\u001b[0m Trial 58 finished with value: 0.8163596207713855 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,184]\u001b[0m Trial 59 finished with value: 0.5666665021425084 and parameters: {'scalers': 'robust', 'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,222]\u001b[0m Trial 60 finished with value: 0.8088705738705737 and parameters: {'scalers': 'minmax', 'n_neighbors': 24, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,261]\u001b[0m Trial 61 finished with value: 0.8163596207713855 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,300]\u001b[0m Trial 62 finished with value: 0.8163596207713855 and parameters: {'scalers': 'minmax', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,340]\u001b[0m Trial 63 finished with value: 0.8019154456654455 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,380]\u001b[0m Trial 64 finished with value: 0.7873227507786331 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,419]\u001b[0m Trial 65 finished with value: 0.8019154456654455 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,460]\u001b[0m Trial 66 finished with value: 0.8091681929181929 and parameters: {'scalers': 'standard', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,498]\u001b[0m Trial 67 finished with value: 0.7606758192787605 and parameters: {'scalers': 'minmax', 'n_neighbors': 1, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,537]\u001b[0m Trial 68 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,578]\u001b[0m Trial 69 finished with value: 0.7885749054866702 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,619]\u001b[0m Trial 70 finished with value: 0.7873227507786331 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,670]\u001b[0m Trial 71 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,709]\u001b[0m Trial 72 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,749]\u001b[0m Trial 73 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,794]\u001b[0m Trial 74 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,833]\u001b[0m Trial 75 finished with value: 0.8168910256410257 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,880]\u001b[0m Trial 76 finished with value: 0.694549372196431 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,923]\u001b[0m Trial 77 finished with value: 0.7873227507786331 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:01,992]\u001b[0m Trial 78 finished with value: 0.7603422802687507 and parameters: {'scalers': 'robust', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,035]\u001b[0m Trial 79 finished with value: 0.8095364439482087 and parameters: {'scalers': 'standard', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,076]\u001b[0m Trial 80 finished with value: 0.8168910256410257 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,116]\u001b[0m Trial 81 finished with value: 0.8168910256410257 and parameters: {'scalers': 'minmax', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,155]\u001b[0m Trial 82 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,195]\u001b[0m Trial 83 finished with value: 0.7864117826617827 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,235]\u001b[0m Trial 84 finished with value: 0.815776184599714 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,272]\u001b[0m Trial 85 finished with value: 0.8089557746175394 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,312]\u001b[0m Trial 86 finished with value: 0.7873227507786331 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,356]\u001b[0m Trial 87 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,396]\u001b[0m Trial 88 finished with value: 0.6787016170104405 and parameters: {'scalers': 'minmax', 'n_neighbors': 20, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,435]\u001b[0m Trial 89 finished with value: 0.8089557746175394 and parameters: {'scalers': 'minmax', 'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,476]\u001b[0m Trial 90 finished with value: 0.7885749054866702 and parameters: {'scalers': 'minmax', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,516]\u001b[0m Trial 91 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,557]\u001b[0m Trial 92 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,600]\u001b[0m Trial 93 finished with value: 0.8171886446886447 and parameters: {'scalers': 'minmax', 'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,638]\u001b[0m Trial 94 finished with value: 0.8019154456654455 and parameters: {'scalers': 'minmax', 'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,677]\u001b[0m Trial 95 finished with value: 0.7932670270905565 and parameters: {'scalers': 'minmax', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,740]\u001b[0m Trial 96 finished with value: 0.775622686137392 and parameters: {'scalers': 'robust', 'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,785]\u001b[0m Trial 97 finished with value: 0.7864117826617827 and parameters: {'scalers': 'minmax', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 49 with value: 0.8171886446886447.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,839]\u001b[0m Trial 98 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,884]\u001b[0m Trial 99 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,926]\u001b[0m Trial 100 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:02,973]\u001b[0m Trial 101 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,015]\u001b[0m Trial 102 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,057]\u001b[0m Trial 103 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,098]\u001b[0m Trial 104 finished with value: 0.8310565904683551 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 98 with value: 0.8310565904683551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,141]\u001b[0m Trial 105 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,183]\u001b[0m Trial 106 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,229]\u001b[0m Trial 107 finished with value: 0.6985425440572499 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,269]\u001b[0m Trial 108 finished with value: 0.7959421216038863 and parameters: {'scalers': 'standard', 'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,311]\u001b[0m Trial 109 finished with value: 0.795145418307183 and parameters: {'scalers': 'standard', 'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,352]\u001b[0m Trial 110 finished with value: 0.781253207576737 and parameters: {'scalers': 'standard', 'n_neighbors': 2, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,392]\u001b[0m Trial 111 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,433]\u001b[0m Trial 112 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,483]\u001b[0m Trial 113 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,527]\u001b[0m Trial 114 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,572]\u001b[0m Trial 115 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,615]\u001b[0m Trial 116 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,656]\u001b[0m Trial 117 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,698]\u001b[0m Trial 118 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,739]\u001b[0m Trial 119 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,781]\u001b[0m Trial 120 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,822]\u001b[0m Trial 121 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,871]\u001b[0m Trial 122 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,914]\u001b[0m Trial 123 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:03,959]\u001b[0m Trial 124 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,002]\u001b[0m Trial 125 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,047]\u001b[0m Trial 126 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,091]\u001b[0m Trial 127 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,136]\u001b[0m Trial 128 finished with value: 0.6985425440572499 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,179]\u001b[0m Trial 129 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,221]\u001b[0m Trial 130 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,262]\u001b[0m Trial 131 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,304]\u001b[0m Trial 132 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,346]\u001b[0m Trial 133 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,387]\u001b[0m Trial 134 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,428]\u001b[0m Trial 135 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,470]\u001b[0m Trial 136 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,515]\u001b[0m Trial 137 finished with value: 0.7655326617826618 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,557]\u001b[0m Trial 138 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,601]\u001b[0m Trial 139 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,646]\u001b[0m Trial 140 finished with value: 0.8102827809445456 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,701]\u001b[0m Trial 141 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,749]\u001b[0m Trial 142 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,791]\u001b[0m Trial 143 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,833]\u001b[0m Trial 144 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,883]\u001b[0m Trial 145 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,925]\u001b[0m Trial 146 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:04,970]\u001b[0m Trial 147 finished with value: 0.8102827809445456 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,011]\u001b[0m Trial 148 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,055]\u001b[0m Trial 149 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,100]\u001b[0m Trial 150 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,145]\u001b[0m Trial 151 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,191]\u001b[0m Trial 152 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,239]\u001b[0m Trial 153 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,282]\u001b[0m Trial 154 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,324]\u001b[0m Trial 155 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,368]\u001b[0m Trial 156 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,413]\u001b[0m Trial 157 finished with value: 0.6985425440572499 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,454]\u001b[0m Trial 158 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,496]\u001b[0m Trial 159 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,541]\u001b[0m Trial 160 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,584]\u001b[0m Trial 161 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,645]\u001b[0m Trial 162 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,693]\u001b[0m Trial 163 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,740]\u001b[0m Trial 164 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,783]\u001b[0m Trial 165 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,825]\u001b[0m Trial 166 finished with value: 0.8026545758163405 and parameters: {'scalers': 'standard', 'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,869]\u001b[0m Trial 167 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,918]\u001b[0m Trial 168 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:05,961]\u001b[0m Trial 169 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,006]\u001b[0m Trial 170 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,049]\u001b[0m Trial 171 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,092]\u001b[0m Trial 172 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,136]\u001b[0m Trial 173 finished with value: 0.8215949083596144 and parameters: {'scalers': 'standard', 'n_neighbors': 29, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,205]\u001b[0m Trial 174 finished with value: 0.7633148224324695 and parameters: {'scalers': 'robust', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,250]\u001b[0m Trial 175 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,294]\u001b[0m Trial 176 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,337]\u001b[0m Trial 177 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,380]\u001b[0m Trial 178 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,423]\u001b[0m Trial 179 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,465]\u001b[0m Trial 180 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,508]\u001b[0m Trial 181 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,558]\u001b[0m Trial 182 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,601]\u001b[0m Trial 183 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,644]\u001b[0m Trial 184 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,688]\u001b[0m Trial 185 finished with value: 0.7019543201896143 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,734]\u001b[0m Trial 186 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,778]\u001b[0m Trial 187 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,822]\u001b[0m Trial 188 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,866]\u001b[0m Trial 189 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,918]\u001b[0m Trial 190 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:06,965]\u001b[0m Trial 191 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,007]\u001b[0m Trial 192 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,052]\u001b[0m Trial 193 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,095]\u001b[0m Trial 194 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,139]\u001b[0m Trial 195 finished with value: 0.7655326617826618 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,182]\u001b[0m Trial 196 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,226]\u001b[0m Trial 197 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,297]\u001b[0m Trial 198 finished with value: 0.7900549205696265 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,340]\u001b[0m Trial 199 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,383]\u001b[0m Trial 200 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,426]\u001b[0m Trial 201 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,469]\u001b[0m Trial 202 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,513]\u001b[0m Trial 203 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,560]\u001b[0m Trial 204 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,604]\u001b[0m Trial 205 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,650]\u001b[0m Trial 206 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,699]\u001b[0m Trial 207 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,754]\u001b[0m Trial 208 finished with value: 0.800261413423178 and parameters: {'scalers': 'standard', 'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,799]\u001b[0m Trial 209 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,842]\u001b[0m Trial 210 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,886]\u001b[0m Trial 211 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,941]\u001b[0m Trial 212 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:07,985]\u001b[0m Trial 213 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,031]\u001b[0m Trial 214 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,090]\u001b[0m Trial 215 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,138]\u001b[0m Trial 216 finished with value: 0.656607142857143 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,181]\u001b[0m Trial 217 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,225]\u001b[0m Trial 218 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,269]\u001b[0m Trial 219 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,314]\u001b[0m Trial 220 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,360]\u001b[0m Trial 221 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,405]\u001b[0m Trial 222 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,450]\u001b[0m Trial 223 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,494]\u001b[0m Trial 224 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,539]\u001b[0m Trial 225 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,584]\u001b[0m Trial 226 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,630]\u001b[0m Trial 227 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,683]\u001b[0m Trial 228 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,727]\u001b[0m Trial 229 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,796]\u001b[0m Trial 230 finished with value: 0.7707284219048925 and parameters: {'scalers': 'robust', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,841]\u001b[0m Trial 231 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,886]\u001b[0m Trial 232 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,942]\u001b[0m Trial 233 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:08,989]\u001b[0m Trial 234 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,034]\u001b[0m Trial 235 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,078]\u001b[0m Trial 236 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,123]\u001b[0m Trial 237 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,169]\u001b[0m Trial 238 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,215]\u001b[0m Trial 239 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,261]\u001b[0m Trial 240 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,307]\u001b[0m Trial 241 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,352]\u001b[0m Trial 242 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,397]\u001b[0m Trial 243 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,443]\u001b[0m Trial 244 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,488]\u001b[0m Trial 245 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,533]\u001b[0m Trial 246 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,589]\u001b[0m Trial 247 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,636]\u001b[0m Trial 248 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,682]\u001b[0m Trial 249 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,731]\u001b[0m Trial 250 finished with value: 0.6954258241758241 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,776]\u001b[0m Trial 251 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,822]\u001b[0m Trial 252 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,869]\u001b[0m Trial 253 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,915]\u001b[0m Trial 254 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:09,971]\u001b[0m Trial 255 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,016]\u001b[0m Trial 256 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,063]\u001b[0m Trial 257 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,110]\u001b[0m Trial 258 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,155]\u001b[0m Trial 259 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,202]\u001b[0m Trial 260 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,248]\u001b[0m Trial 261 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,318]\u001b[0m Trial 262 finished with value: 0.7713738222561752 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,365]\u001b[0m Trial 263 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,410]\u001b[0m Trial 264 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,456]\u001b[0m Trial 265 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,506]\u001b[0m Trial 266 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,555]\u001b[0m Trial 267 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,601]\u001b[0m Trial 268 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,652]\u001b[0m Trial 269 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,700]\u001b[0m Trial 270 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,746]\u001b[0m Trial 271 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,792]\u001b[0m Trial 272 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,841]\u001b[0m Trial 273 finished with value: 0.6954258241758241 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,889]\u001b[0m Trial 274 finished with value: 0.7674531106148753 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,940]\u001b[0m Trial 275 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:10,996]\u001b[0m Trial 276 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,042]\u001b[0m Trial 277 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,090]\u001b[0m Trial 278 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,137]\u001b[0m Trial 279 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,182]\u001b[0m Trial 280 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,230]\u001b[0m Trial 281 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,300]\u001b[0m Trial 282 finished with value: 0.7633148224324695 and parameters: {'scalers': 'robust', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,346]\u001b[0m Trial 283 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,394]\u001b[0m Trial 284 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,444]\u001b[0m Trial 285 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,491]\u001b[0m Trial 286 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,541]\u001b[0m Trial 287 finished with value: 0.7674531106148753 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,588]\u001b[0m Trial 288 finished with value: 0.8022551223286516 and parameters: {'scalers': 'standard', 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,635]\u001b[0m Trial 289 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,687]\u001b[0m Trial 290 finished with value: 0.6954258241758241 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,735]\u001b[0m Trial 291 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,782]\u001b[0m Trial 292 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,828]\u001b[0m Trial 293 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,879]\u001b[0m Trial 294 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,933]\u001b[0m Trial 295 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:11,979]\u001b[0m Trial 296 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,036]\u001b[0m Trial 297 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,083]\u001b[0m Trial 298 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,131]\u001b[0m Trial 299 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,176]\u001b[0m Trial 300 finished with value: 0.8102827809445456 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,221]\u001b[0m Trial 301 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,268]\u001b[0m Trial 302 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,339]\u001b[0m Trial 303 finished with value: 0.7972058578676225 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,385]\u001b[0m Trial 304 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,430]\u001b[0m Trial 305 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,476]\u001b[0m Trial 306 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,524]\u001b[0m Trial 307 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,572]\u001b[0m Trial 308 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,636]\u001b[0m Trial 309 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,691]\u001b[0m Trial 310 finished with value: 0.6875019343401696 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,742]\u001b[0m Trial 311 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,791]\u001b[0m Trial 312 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,837]\u001b[0m Trial 313 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,884]\u001b[0m Trial 314 finished with value: 0.81627442002442 and parameters: {'scalers': 'standard', 'n_neighbors': 27, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,933]\u001b[0m Trial 315 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:12,996]\u001b[0m Trial 316 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,053]\u001b[0m Trial 317 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,101]\u001b[0m Trial 318 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,149]\u001b[0m Trial 319 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,196]\u001b[0m Trial 320 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,252]\u001b[0m Trial 321 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,301]\u001b[0m Trial 322 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,347]\u001b[0m Trial 323 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,393]\u001b[0m Trial 324 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,464]\u001b[0m Trial 325 finished with value: 0.7493553015611839 and parameters: {'scalers': 'robust', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,510]\u001b[0m Trial 326 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,558]\u001b[0m Trial 327 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,604]\u001b[0m Trial 328 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,651]\u001b[0m Trial 329 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,698]\u001b[0m Trial 330 finished with value: 0.7655326617826618 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,749]\u001b[0m Trial 331 finished with value: 0.6985425440572499 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,798]\u001b[0m Trial 332 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,857]\u001b[0m Trial 333 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,908]\u001b[0m Trial 334 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:13,961]\u001b[0m Trial 335 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,013]\u001b[0m Trial 336 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,071]\u001b[0m Trial 337 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,120]\u001b[0m Trial 338 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,168]\u001b[0m Trial 339 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,217]\u001b[0m Trial 340 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,267]\u001b[0m Trial 341 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,313]\u001b[0m Trial 342 finished with value: 0.8026545758163405 and parameters: {'scalers': 'standard', 'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,359]\u001b[0m Trial 343 finished with value: 0.7674531106148753 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,405]\u001b[0m Trial 344 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,460]\u001b[0m Trial 345 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,535]\u001b[0m Trial 346 finished with value: 0.7972058578676225 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,585]\u001b[0m Trial 347 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,630]\u001b[0m Trial 348 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,679]\u001b[0m Trial 349 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,730]\u001b[0m Trial 350 finished with value: 0.7019543201896143 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,779]\u001b[0m Trial 351 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,826]\u001b[0m Trial 352 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,876]\u001b[0m Trial 353 finished with value: 0.7655326617826618 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,922]\u001b[0m Trial 354 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:14,971]\u001b[0m Trial 355 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,018]\u001b[0m Trial 356 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,082]\u001b[0m Trial 357 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,130]\u001b[0m Trial 358 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,180]\u001b[0m Trial 359 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,228]\u001b[0m Trial 360 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,275]\u001b[0m Trial 361 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,325]\u001b[0m Trial 362 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,371]\u001b[0m Trial 363 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,421]\u001b[0m Trial 364 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,468]\u001b[0m Trial 365 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,515]\u001b[0m Trial 366 finished with value: 0.8093312324929972 and parameters: {'scalers': 'standard', 'n_neighbors': 23, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,594]\u001b[0m Trial 367 finished with value: 0.7900549205696265 and parameters: {'scalers': 'robust', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,645]\u001b[0m Trial 368 finished with value: 0.7019543201896143 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,700]\u001b[0m Trial 369 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,749]\u001b[0m Trial 370 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,798]\u001b[0m Trial 371 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,846]\u001b[0m Trial 372 finished with value: 0.8097608029225676 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,892]\u001b[0m Trial 373 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,943]\u001b[0m Trial 374 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:15,990]\u001b[0m Trial 375 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,038]\u001b[0m Trial 376 finished with value: 0.7655326617826618 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,095]\u001b[0m Trial 377 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,145]\u001b[0m Trial 378 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,193]\u001b[0m Trial 379 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,243]\u001b[0m Trial 380 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,291]\u001b[0m Trial 381 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,340]\u001b[0m Trial 382 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,390]\u001b[0m Trial 383 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,439]\u001b[0m Trial 384 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,488]\u001b[0m Trial 385 finished with value: 0.8019494476112122 and parameters: {'scalers': 'standard', 'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,540]\u001b[0m Trial 386 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,592]\u001b[0m Trial 387 finished with value: 0.7674531106148753 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,672]\u001b[0m Trial 388 finished with value: 0.7633148224324695 and parameters: {'scalers': 'robust', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,726]\u001b[0m Trial 389 finished with value: 0.6954258241758241 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,777]\u001b[0m Trial 390 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,827]\u001b[0m Trial 391 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,877]\u001b[0m Trial 392 finished with value: 0.7942872405372405 and parameters: {'scalers': 'standard', 'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,929]\u001b[0m Trial 393 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:16,981]\u001b[0m Trial 394 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,030]\u001b[0m Trial 395 finished with value: 0.8097608029225676 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,081]\u001b[0m Trial 396 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,142]\u001b[0m Trial 397 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,191]\u001b[0m Trial 398 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,242]\u001b[0m Trial 399 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,293]\u001b[0m Trial 400 finished with value: 0.8102827809445456 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,341]\u001b[0m Trial 401 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,387]\u001b[0m Trial 402 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,433]\u001b[0m Trial 403 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,482]\u001b[0m Trial 404 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,540]\u001b[0m Trial 405 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,588]\u001b[0m Trial 406 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,640]\u001b[0m Trial 407 finished with value: 0.6684454838247408 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,690]\u001b[0m Trial 408 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,739]\u001b[0m Trial 409 finished with value: 0.7674531106148753 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,788]\u001b[0m Trial 410 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,862]\u001b[0m Trial 411 finished with value: 0.7900263706881354 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,910]\u001b[0m Trial 412 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:17,962]\u001b[0m Trial 413 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,011]\u001b[0m Trial 414 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,061]\u001b[0m Trial 415 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,116]\u001b[0m Trial 416 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,171]\u001b[0m Trial 417 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,222]\u001b[0m Trial 418 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,272]\u001b[0m Trial 419 finished with value: 0.7959421216038863 and parameters: {'scalers': 'standard', 'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,322]\u001b[0m Trial 420 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,368]\u001b[0m Trial 421 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,415]\u001b[0m Trial 422 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,463]\u001b[0m Trial 423 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,514]\u001b[0m Trial 424 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,566]\u001b[0m Trial 425 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,619]\u001b[0m Trial 426 finished with value: 0.7019543201896143 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,668]\u001b[0m Trial 427 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,717]\u001b[0m Trial 428 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,770]\u001b[0m Trial 429 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,820]\u001b[0m Trial 430 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,876]\u001b[0m Trial 431 finished with value: 0.7885485347985348 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,925]\u001b[0m Trial 432 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:18,982]\u001b[0m Trial 433 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,033]\u001b[0m Trial 434 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,110]\u001b[0m Trial 435 finished with value: 0.7900263706881354 and parameters: {'scalers': 'robust', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,169]\u001b[0m Trial 436 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,220]\u001b[0m Trial 437 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,270]\u001b[0m Trial 438 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,319]\u001b[0m Trial 439 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,367]\u001b[0m Trial 440 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,416]\u001b[0m Trial 441 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,465]\u001b[0m Trial 442 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,515]\u001b[0m Trial 443 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,565]\u001b[0m Trial 444 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,614]\u001b[0m Trial 445 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,672]\u001b[0m Trial 446 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,728]\u001b[0m Trial 447 finished with value: 0.6800628048422166 and parameters: {'scalers': 'standard', 'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,777]\u001b[0m Trial 448 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,826]\u001b[0m Trial 449 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,876]\u001b[0m Trial 450 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,924]\u001b[0m Trial 451 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:19,977]\u001b[0m Trial 452 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,025]\u001b[0m Trial 453 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,075]\u001b[0m Trial 454 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,155]\u001b[0m Trial 455 finished with value: 0.7972058578676225 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,213]\u001b[0m Trial 456 finished with value: 0.7885485347985348 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,266]\u001b[0m Trial 457 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,317]\u001b[0m Trial 458 finished with value: 0.8080079316108728 and parameters: {'scalers': 'standard', 'n_neighbors': 28, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,366]\u001b[0m Trial 459 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,422]\u001b[0m Trial 460 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,474]\u001b[0m Trial 461 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,524]\u001b[0m Trial 462 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,584]\u001b[0m Trial 463 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,631]\u001b[0m Trial 464 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,681]\u001b[0m Trial 465 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,733]\u001b[0m Trial 466 finished with value: 0.66851812403283 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,783]\u001b[0m Trial 467 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,832]\u001b[0m Trial 468 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,882]\u001b[0m Trial 469 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,935]\u001b[0m Trial 470 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:20,987]\u001b[0m Trial 471 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,037]\u001b[0m Trial 472 finished with value: 0.781253207576737 and parameters: {'scalers': 'standard', 'n_neighbors': 1, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,088]\u001b[0m Trial 473 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,143]\u001b[0m Trial 474 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,203]\u001b[0m Trial 475 finished with value: 0.7741838798456445 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,276]\u001b[0m Trial 476 finished with value: 0.7972058578676225 and parameters: {'scalers': 'robust', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,331]\u001b[0m Trial 477 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,381]\u001b[0m Trial 478 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,431]\u001b[0m Trial 479 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,489]\u001b[0m Trial 480 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,542]\u001b[0m Trial 481 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,594]\u001b[0m Trial 482 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,644]\u001b[0m Trial 483 finished with value: 0.8097608029225676 and parameters: {'scalers': 'standard', 'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,697]\u001b[0m Trial 484 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,752]\u001b[0m Trial 485 finished with value: 0.6954258241758241 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,803]\u001b[0m Trial 486 finished with value: 0.8318269230769232 and parameters: {'scalers': 'standard', 'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,854]\u001b[0m Trial 487 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,905]\u001b[0m Trial 488 finished with value: 0.7853783063341887 and parameters: {'scalers': 'minmax', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:21,959]\u001b[0m Trial 489 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,009]\u001b[0m Trial 490 finished with value: 0.8022551223286516 and parameters: {'scalers': 'standard', 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,061]\u001b[0m Trial 491 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,115]\u001b[0m Trial 492 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,166]\u001b[0m Trial 493 finished with value: 0.8106776556776556 and parameters: {'scalers': 'standard', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,224]\u001b[0m Trial 494 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,278]\u001b[0m Trial 495 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,330]\u001b[0m Trial 496 finished with value: 0.8115201465201466 and parameters: {'scalers': 'standard', 'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,382]\u001b[0m Trial 497 finished with value: 0.8103067765567765 and parameters: {'scalers': 'standard', 'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,435]\u001b[0m Trial 498 finished with value: 0.832293956043956 and parameters: {'scalers': 'standard', 'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n",
            "\u001b[32m[I 2022-11-27 10:26:22,520]\u001b[0m Trial 499 finished with value: 0.7707284219048925 and parameters: {'scalers': 'robust', 'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 105 with value: 0.832293956043956.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "kNN_sampler = TPESampler(seed=42) # create a seed for the sampler for reproducibility\n",
        "kNN_study = optuna.create_study(direction=\"maximize\", sampler=kNN_sampler)\n",
        "kNN_study.optimize(kNN_objective, n_trials=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Wp_6GXS62I2q",
        "outputId": "20fd8340-d469-4b24-8296-e9e73aea4dd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"62bdf25f-274f-4b72-afa8-c0c72edb91cb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"62bdf25f-274f-4b72-afa8-c0c72edb91cb\")) {                    Plotly.newPlot(                        \"62bdf25f-274f-4b72-afa8-c0c72edb91cb\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.660348255975191,0.524051807325801,0.7557441904500728,0.6150520652378237,0.7879598600573832,0.8163596207713855,0.7518192918192919,0.7032097069597069,0.6912083259877376,0.7788958916900094,0.7793303755068461,0.7885749054866702,0.7864117826617827,0.7788958916900094,0.7984205023562608,0.785785684903332,0.7984205023562608,0.7606758192787605,0.8022836966954614,0.8093899238016885,0.7791485720162191,0.8022836966954614,0.815776184599714,0.815776184599714,0.815776184599714,0.815776184599714,0.6668712986360045,0.7853783063341887,0.795145418307183,0.5537839611369023,0.7939274695892342,0.815776184599714,0.7797521187962364,0.8017617186734833,0.5976643862673274,0.7932670270905565,0.8017617186734833,0.7819806663924311,0.6513252528345408,0.7793303755068461,0.5754850962590901,0.7932670270905565,0.815776184599714,0.7797521187962364,0.8017617186734833,0.7864117826617827,0.7939274695892342,0.8023824786324786,0.7932670270905565,0.8171886446886447,0.8019154456654455,0.8168910256410257,0.8089557746175394,0.8171886446886447,0.7864117826617827,0.7885749054866702,0.8163596207713855,0.7875507907125554,0.8163596207713855,0.5666665021425084,0.8088705738705737,0.8163596207713855,0.8163596207713855,0.8019154456654455,0.7873227507786331,0.8019154456654455,0.8091681929181929,0.7606758192787605,0.8171886446886447,0.7885749054866702,0.7873227507786331,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8168910256410257,0.694549372196431,0.7873227507786331,0.7603422802687507,0.8095364439482087,0.8168910256410257,0.8168910256410257,0.8171886446886447,0.7864117826617827,0.815776184599714,0.8089557746175394,0.7873227507786331,0.8171886446886447,0.6787016170104405,0.8089557746175394,0.7885749054866702,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8019154456654455,0.7932670270905565,0.775622686137392,0.7864117826617827,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.832293956043956,0.8115201465201466,0.6985425440572499,0.7959421216038863,0.795145418307183,0.781253207576737,0.8318269230769232,0.8318269230769232,0.8318269230769232,0.8318269230769232,0.8106776556776556,0.8318269230769232,0.8103067765567765,0.8318269230769232,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.8115201465201466,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.6985425440572499,0.832293956043956,0.8115201465201466,0.8106776556776556,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.7655326617826618,0.832293956043956,0.8115201465201466,0.8102827809445456,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.832293956043956,0.8103067765567765,0.8102827809445456,0.8106776556776556,0.8103067765567765,0.8115201465201466,0.832293956043956,0.832293956043956,0.8106776556776556,0.832293956043956,0.8106776556776556,0.8103067765567765,0.6985425440572499,0.8103067765567765,0.8115201465201466,0.7741838798456445,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.8026545758163405,0.8103067765567765,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.832293956043956,0.8215949083596144,0.7633148224324695,0.8103067765567765,0.8106776556776556,0.832293956043956,0.8106776556776556,0.832293956043956,0.832293956043956,0.832293956043956,0.8103067765567765,0.8115201465201466,0.8106776556776556,0.7019543201896143,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.832293956043956,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.7655326617826618,0.8103067765567765,0.832293956043956,0.7900549205696265,0.8115201465201466,0.832293956043956,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.800261413423178,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.656607142857143,0.8103067765567765,0.832293956043956,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8115201465201466,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.7707284219048925,0.832293956043956,0.832293956043956,0.8103067765567765,0.832293956043956,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8115201465201466,0.6954258241758241,0.8103067765567765,0.7741838798456445,0.8318269230769232,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.7713738222561752,0.832293956043956,0.8106776556776556,0.8103067765567765,0.8115201465201466,0.832293956043956,0.8103067765567765,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.6954258241758241,0.7674531106148753,0.832293956043956,0.8318269230769232,0.8106776556776556,0.832293956043956,0.832293956043956,0.8106776556776556,0.832293956043956,0.7633148224324695,0.8103067765567765,0.8106776556776556,0.832293956043956,0.832293956043956,0.7674531106148753,0.8022551223286516,0.8318269230769232,0.6954258241758241,0.8103067765567765,0.8115201465201466,0.832293956043956,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8106776556776556,0.7741838798456445,0.8102827809445456,0.8318269230769232,0.832293956043956,0.7972058578676225,0.8115201465201466,0.8106776556776556,0.832293956043956,0.832293956043956,0.8103067765567765,0.832293956043956,0.6875019343401696,0.8103067765567765,0.832293956043956,0.8106776556776556,0.81627442002442,0.8103067765567765,0.8318269230769232,0.8106776556776556,0.832293956043956,0.7741838798456445,0.8103067765567765,0.8115201465201466,0.8106776556776556,0.832293956043956,0.8103067765567765,0.7493553015611839,0.8103067765567765,0.832293956043956,0.832293956043956,0.8318269230769232,0.7655326617826618,0.6985425440572499,0.8103067765567765,0.832293956043956,0.8106776556776556,0.832293956043956,0.8115201465201466,0.8103067765567765,0.832293956043956,0.8318269230769232,0.8106776556776556,0.832293956043956,0.8026545758163405,0.7674531106148753,0.8106776556776556,0.832293956043956,0.7972058578676225,0.8106776556776556,0.832293956043956,0.832293956043956,0.7019543201896143,0.8115201465201466,0.832293956043956,0.7655326617826618,0.832293956043956,0.8103067765567765,0.8318269230769232,0.8106776556776556,0.832293956043956,0.8103067765567765,0.8106776556776556,0.8103067765567765,0.8106776556776556,0.8115201465201466,0.7741838798456445,0.832293956043956,0.8093312324929972,0.7900549205696265,0.7019543201896143,0.832293956043956,0.8106776556776556,0.8103067765567765,0.8097608029225676,0.832293956043956,0.832293956043956,0.832293956043956,0.7655326617826618,0.832293956043956,0.8103067765567765,0.8115201465201466,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8106776556776556,0.8318269230769232,0.8019494476112122,0.832293956043956,0.7674531106148753,0.7633148224324695,0.6954258241758241,0.832293956043956,0.8103067765567765,0.7942872405372405,0.8103067765567765,0.832293956043956,0.8097608029225676,0.8106776556776556,0.832293956043956,0.8106776556776556,0.7741838798456445,0.8102827809445456,0.8103067765567765,0.8318269230769232,0.832293956043956,0.8106776556776556,0.832293956043956,0.8103067765567765,0.6684454838247408,0.8106776556776556,0.7674531106148753,0.832293956043956,0.7900263706881354,0.832293956043956,0.8106776556776556,0.8103067765567765,0.8318269230769232,0.8106776556776556,0.832293956043956,0.8103067765567765,0.7959421216038863,0.7741838798456445,0.8106776556776556,0.832293956043956,0.8103067765567765,0.8115201465201466,0.8106776556776556,0.7019543201896143,0.8106776556776556,0.832293956043956,0.832293956043956,0.832293956043956,0.7885485347985348,0.8103067765567765,0.8103067765567765,0.8106776556776556,0.7900263706881354,0.8115201465201466,0.8106776556776556,0.832293956043956,0.8103067765567765,0.8106776556776556,0.832293956043956,0.8318269230769232,0.7741838798456445,0.8103067765567765,0.832293956043956,0.832293956043956,0.6800628048422166,0.8106776556776556,0.832293956043956,0.8103067765567765,0.832293956043956,0.8115201465201466,0.8106776556776556,0.832293956043956,0.7972058578676225,0.7885485347985348,0.832293956043956,0.8080079316108728,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8115201465201466,0.8106776556776556,0.8103067765567765,0.832293956043956,0.66851812403283,0.8103067765567765,0.832293956043956,0.8103067765567765,0.832293956043956,0.8106776556776556,0.781253207576737,0.8115201465201466,0.8318269230769232,0.7741838798456445,0.7972058578676225,0.8106776556776556,0.832293956043956,0.832293956043956,0.8106776556776556,0.8103067765567765,0.832293956043956,0.8097608029225676,0.832293956043956,0.6954258241758241,0.8318269230769232,0.8103067765567765,0.7853783063341887,0.832293956043956,0.8022551223286516,0.832293956043956,0.8103067765567765,0.8106776556776556,0.832293956043956,0.832293956043956,0.8115201465201466,0.8103067765567765,0.832293956043956,0.7707284219048925],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.660348255975191,0.660348255975191,0.7557441904500728,0.7557441904500728,0.7879598600573832,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8163596207713855,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8171886446886447,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.8310565904683551,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956,0.832293956043956],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('62bdf25f-274f-4b72-afa8-c0c72edb91cb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(kNN_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "DK18b5Cv27hq",
        "outputId": "8e6d2877-285c-4274-a687-e8587a79fd12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f5c7a7ed-7e81-4182-aa1a-342fea5dff30\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f5c7a7ed-7e81-4182-aa1a-342fea5dff30\")) {                    Plotly.newPlot(                        \"f5c7a7ed-7e81-4182-aa1a-342fea5dff30\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"metric (CategoricalDistribution): 0.004998128964034069<extra></extra>\",\"n_neighbors (IntDistribution): 0.02720045826474656<extra></extra>\",\"scalers (CategoricalDistribution): 0.06785893235362296<extra></extra>\",\"weights (CategoricalDistribution): 0.8999424804175964<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"0.03\",\"0.07\",\"0.90\"],\"textposition\":\"outside\",\"x\":[0.004998128964034069,0.02720045826474656,0.06785893235362296,0.8999424804175964],\"y\":[\"metric\",\"n_neighbors\",\"scalers\",\"weights\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f5c7a7ed-7e81-4182-aa1a-342fea5dff30');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_param_importances(kNN_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLdayxJF2MQe",
        "outputId": "457cabda-212b-4416-ab2a-cb9755235a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters after tuning using mean accuracy:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'scalers': 'standard',\n",
              " 'n_neighbors': 11,\n",
              " 'weights': 'distance',\n",
              " 'metric': 'manhattan'}"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Best parameters after tuning using mean accuracy:\")\n",
        "kNN_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PftkUrRh3RHE",
        "outputId": "0dcc2ab4-926e-44a9-abb9-7b59d73872bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος train και test: 0.056992530822753906 seconds\n",
            "Training Set:\n",
            "kNN Classifier accuracy:  0.8333333333333334\n",
            "kNN Classifier f1 macro:  0.832293956043956\n",
            "\n",
            "Testing set:\n",
            "kNN Classifier accuracy:  0.92\n",
            "kNN Classifier f1 macro:  0.9178981937602627\n",
            "\n",
            "kNN Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.90      0.90        21\n",
            "         1.0       0.93      0.93      0.93        29\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.92      0.92      0.92        50\n",
            "weighted avg       0.92      0.92      0.92        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_params = kNN_study.best_params\n",
        "\n",
        "if best_params['scalers'] == \"minmax\":\n",
        "  opt_scaler = MinMaxScaler()\n",
        "elif best_params['scalers'] == \"standard\":\n",
        "  opt_scaler = StandardScaler()\n",
        "else:\n",
        "  opt_scaler = RobustScaler()\n",
        "\n",
        "del best_params['scalers']\n",
        "\n",
        "# Creation of knn classifier with optimized parameters\n",
        "kNN_clf_opt = neighbors.KNeighborsClassifier(**best_params)\n",
        "kNN_pipeline = make_pipeline(opt_scaler, kNN_clf_opt)\n",
        "\n",
        "# Kαταγραφή χρόνου train και test\n",
        "start_time = time.time()\n",
        "\n",
        "# Model training \n",
        "strtfdKFold = StratifiedKFold(n_splits=10)\n",
        "# Creation of knn classifier with optimized parameters\n",
        "clf = neighbors.KNeighborsClassifier(**best_params)\n",
        "kNN_pipeline = make_pipeline(opt_scaler, clf)\n",
        "\n",
        "# Model testing\n",
        "kNN_pipeline.fit(x_train, y_train)\n",
        "kNN_scores_f1 = cross_val_score(kNN_pipeline, x_train, y_train, scoring='accuracy' ,cv = strtfdKFold, n_jobs=1)\n",
        "kNN_f1_macro_f1 = cross_val_score(kNN_pipeline, x_train, y_train, scoring='f1_macro', cv = strtfdKFold, n_jobs=1)\n",
        "\n",
        "# Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(\"kNN Classifier accuracy: \", kNN_scores_f1.mean())\n",
        "print(\"kNN Classifier f1 macro: \", kNN_f1_macro_f1.mean())\n",
        "\n",
        "knn_test_acc_f1 = kNN_pipeline.score(x_test, y_test)\n",
        "kNN_preds_f1 = kNN_pipeline.predict(x_test)\n",
        "knn_f1_f1 = f1_score(y_test, kNN_preds_f1, average='macro')\n",
        "\n",
        "print(\"\\nTesting set:\")\n",
        "print(\"kNN Classifier accuracy: \", knn_test_acc_f1)\n",
        "print(\"kNN Classifier f1 macro: \", knn_f1_f1)\n",
        "print('\\nkNN Classifier Classification Report:\\n' + classification_report(y_test, kNN_preds_f1)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJqlu3obQTSr"
      },
      "source": [
        "Με τις βέλτιστες παραμέτρους που προέκυψαν από το optuna υπάρχει βελτίωση και στις 2 μετρικές της τάξης του 5-7% για το training set. Παρατηρούμε για το test set όμως, ότι τόσο το accuracy όσο και το f1-macro score μειώνονται σε σχέση με τα αντίστοιχα του training set, οδηγώντας μας στο να συμπεράνουμε ότι υπάρχει overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO1SCWMIOrFf"
      },
      "source": [
        "### Logistic Regression (LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "qDhVhm0RfhUq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "logModel = LogisticRegression()\n",
        "\n",
        "param_grid = [    \n",
        "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'], #Loss function\n",
        "    'C' : np.logspace(-1, 1, 40), \n",
        "    'solver' : ['lbfgs','newton-cg','liblinear','sag',], #'saga'\n",
        "    'max_iter' : [100] #100, 500, 1000, 2500, 5000\n",
        "    }\n",
        "]\n",
        "#Cause of warnings (εκτός της μη-σύγκλισης λόγο χαμηλού αριθμού max_iterations)\n",
        "#solvers :  {'lbfgs', 'newton-cg', 'sag'} support l2 or no Loss function\n",
        "#solver 'liblinear' supports does not support Elastic net Loss function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dITpcE2IrI2Q",
        "outputId": "a724961a-ff11-4f65-c75a-d4e195386669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 640 candidates, totalling 6400 fits\n",
            "Συνολικός χρόνος train και test: 143.36900544166565 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "3200 fits failed out of a total of 6400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan        nan 0.79666667        nan 0.72619048 0.80380952\n",
            " 0.80333333 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.81047619        nan 0.73333333 0.80380952 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.81047619        nan\n",
            " 0.73333333 0.80380952 0.80380952 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.80333333        nan 0.71190476 0.80380952\n",
            " 0.80380952 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.81047619        nan 0.75428571 0.81095238 0.79666667 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.81047619        nan\n",
            " 0.72619048 0.80380952 0.79666667 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81761905        nan 0.71238095 0.80380952\n",
            " 0.78238095 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.81761905        nan 0.74809524 0.80380952 0.8247619  0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.81761905        nan\n",
            " 0.73333333 0.79666667 0.81047619 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81047619        nan 0.76809524 0.79666667\n",
            " 0.81095238 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.80333333        nan 0.74809524 0.79666667 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.79619048        nan\n",
            " 0.71238095 0.79666667 0.78952381 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81761905        nan 0.72619048 0.79666667\n",
            " 0.81095238 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.79619048        nan 0.72666667 0.79666667 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.79619048        nan\n",
            " 0.72666667 0.79666667 0.80380952 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.79619048        nan 0.73380952 0.78952381\n",
            " 0.80380952 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.79619048        nan 0.72666667 0.79666667 0.79619048 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78904762        nan\n",
            " 0.69809524 0.78238095 0.78952381 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.7752381         nan 0.74095238 0.78952381\n",
            " 0.79666667 0.49428571        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.7752381         nan 0.71952381 0.79666667 0.81761905 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.71952381 0.78238095 0.80333333 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.7752381         nan 0.72666667 0.78238095\n",
            " 0.81761905 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.74666667 0.78238095 0.81047619 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.71904762 0.78238095 0.81095238 0.51571429        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78238095        nan 0.75380952 0.78238095\n",
            " 0.80380952 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78238095        nan 0.73952381 0.78952381 0.79666667 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.7752381         nan\n",
            " 0.72666667 0.78238095 0.80333333 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78238095        nan 0.71238095 0.78238095\n",
            " 0.78952381 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.69809524 0.78238095 0.79619048 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.7752381         nan\n",
            " 0.73428571 0.78238095 0.81047619 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.73380952 0.78238095\n",
            " 0.81047619 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.73380952 0.78238095 0.79666667 0.51571429\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78238095        nan\n",
            " 0.72666667 0.78238095 0.79666667 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.73380952 0.78952381\n",
            " 0.79666667 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.7052381  0.78238095 0.78238095 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.71952381 0.78238095 0.79619048 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.71952381 0.78238095\n",
            " 0.79666667 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.73333333 0.78238095 0.80380952 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.73238095 0.78238095 0.81761905 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.74666667 0.78238095\n",
            " 0.81047619 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Accuracy training for Logistic Regression Model\n",
        "\n",
        "#Searching for the optimal parameters \n",
        "with warnings.catch_warnings(record=True): \n",
        "  lr_opt_accuracy_train = GridSearchCV(logModel, param_grid = param_grid, cv = 10, verbose=True, scoring='accuracy', n_jobs=-1, )\n",
        "\n",
        "#Applying the best parameters & Καταγραφή χρόνου train και test\n",
        "start_time = time.time()\n",
        "optimised_accuracy_lr_model = lr_opt_accuracy_train.fit(x_train,y_train)\n",
        "\n",
        "#Evaluating...\n",
        "predictions_accuracy_model = optimised_accuracy_lr_model.predict(x_test)\n",
        "optimised_accuracy_lr_model_accuracy_test = optimised_accuracy_lr_model.score(x_test, y_test)\n",
        "\n",
        "#Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj0EKq6ZydnZ",
        "outputId": "05cd12e7-ba60-44bb-c932-a1fedc27ec85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model optimised on Accuracy\n",
            "Training Set:\n",
            "LR Accuracy - : 0.838\n",
            "\n",
            "Test set:\n",
            "LR accuracy:  0.76\n",
            "\n",
            "LR Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.52      0.58        21\n",
            "         1.0       0.70      0.79      0.74        29\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.67      0.66      0.66        50\n",
            "weighted avg       0.68      0.68      0.67        50\n",
            "\n",
            "\n",
            "LogisticRegression(C=0.22854638641349906, solver='liblinear')\n",
            "{'C': 0.22854638641349906, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Logistic Regression Model optimised on Accuracy\")\n",
        "\n",
        "# Training set accuracy score\n",
        "print(\"Training Set:\")\n",
        "print (f'LR Accuracy - : {optimised_accuracy_lr_model.score(x_train,y_train):.3f}')\n",
        "\n",
        "\n",
        "# Test set accuracy score and Classification Report\n",
        "print(\"\\nTest set:\")\n",
        "print(\"LR accuracy: \", optimised_accuracy_lr_model_accuracy_test)\n",
        "print('\\nLR Classification Report:\\n' + classification_report(y_test, LR_predictions)+'\\n')\n",
        "\n",
        "# Best parameters\n",
        "print(lr_opt_accuracy_train.best_estimator_)\n",
        "print(lr_opt_accuracy_train.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8sH31xjq7p3",
        "outputId": "ce500aa5-a49d-4ae1-f27d-69ede47da251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 640 candidates, totalling 6400 fits\n",
            "Συνολικός χρόνος train και test: 144.6497664451599 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "3200 fits failed out of a total of 6400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan        nan 0.80333333        nan 0.72619048 0.80380952\n",
            " 0.80333333 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.80333333        nan 0.73333333 0.80380952 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.80333333        nan\n",
            " 0.73333333 0.80380952 0.80380952 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81047619        nan 0.71190476 0.80380952\n",
            " 0.80380952 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50142857        nan        nan\n",
            " 0.81761905        nan 0.75428571 0.81095238 0.79666667 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50142857        nan        nan 0.80333333        nan\n",
            " 0.72619048 0.80380952 0.79666667 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81761905        nan 0.71238095 0.80380952\n",
            " 0.78238095 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.81761905        nan 0.74809524 0.80380952 0.8247619  0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.81761905        nan\n",
            " 0.73333333 0.79666667 0.81047619 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81047619        nan 0.76809524 0.79666667\n",
            " 0.81095238 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.81761905        nan 0.74809524 0.79666667 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.81047619        nan\n",
            " 0.71238095 0.79666667 0.78952381 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.49428571\n",
            "        nan        nan 0.81047619        nan 0.72619048 0.79666667\n",
            " 0.81095238 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.80333333        nan 0.72666667 0.79666667 0.78952381 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.80333333        nan\n",
            " 0.72666667 0.79666667 0.80380952 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.81047619        nan 0.73380952 0.78952381\n",
            " 0.80380952 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78904762        nan 0.72666667 0.79666667 0.79619048 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.79619048        nan\n",
            " 0.69809524 0.78238095 0.78952381 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.7752381         nan 0.74095238 0.78952381\n",
            " 0.79666667 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.7752381         nan 0.71952381 0.79666667 0.81761905 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.7752381         nan\n",
            " 0.71952381 0.78238095 0.80333333 0.51571429        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78238095        nan 0.72666667 0.78238095\n",
            " 0.81761905 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.51571429        nan        nan\n",
            " 0.78238095        nan 0.74666667 0.78238095 0.81047619 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.7752381         nan\n",
            " 0.71904762 0.78238095 0.81095238 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.7752381         nan 0.75380952 0.78238095\n",
            " 0.80380952 0.51571429        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.7752381         nan 0.73952381 0.78952381 0.79666667 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78238095        nan\n",
            " 0.72666667 0.78238095 0.80333333 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.71238095 0.78238095\n",
            " 0.78952381 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.7752381         nan 0.69809524 0.78238095 0.79619048 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78238095        nan\n",
            " 0.73428571 0.78238095 0.81047619 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.7752381         nan 0.73380952 0.78238095\n",
            " 0.81047619 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78238095        nan 0.73380952 0.78238095 0.79666667 0.49428571\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50142857        nan        nan 0.78238095        nan\n",
            " 0.72666667 0.78238095 0.79666667 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.49428571\n",
            "        nan        nan 0.78238095        nan 0.73380952 0.78952381\n",
            " 0.79666667 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.7052381  0.78238095 0.78238095 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.71952381 0.78238095 0.79619048 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.71952381 0.78238095\n",
            " 0.79666667 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143        nan        nan\n",
            " 0.78952381        nan 0.73333333 0.78238095 0.80380952 0.50857143\n",
            "        nan        nan        nan        nan 0.72666667 0.78238095\n",
            "        nan 0.50857143        nan        nan 0.78952381        nan\n",
            " 0.73238095 0.78238095 0.81761905 0.50857143        nan        nan\n",
            "        nan        nan 0.72666667 0.78238095        nan 0.50857143\n",
            "        nan        nan 0.78952381        nan 0.74666667 0.78238095\n",
            " 0.81047619 0.50857143        nan        nan        nan        nan\n",
            " 0.72666667 0.78238095        nan 0.50857143]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#F1 score training for Logistic Regression Model\n",
        "\n",
        "#Searching for the optimal parameters \n",
        "with warnings.catch_warnings(record=True): \n",
        "  lr_opt_f1_macro_train = GridSearchCV(logModel, param_grid = param_grid, cv = 10, verbose=True, scoring='f1_macro', n_jobs=-1, )\n",
        "\n",
        "#Applying the best parameters & Καταγραφή χρόνου train και test \n",
        "start_time = time.time()\n",
        "optimised_f1_macro_lr_model = lr_opt_accuracy_train.fit(x_train,y_train)\n",
        "\n",
        "#Evaluating...\n",
        "predictions_f1_macro_model = optimised_f1_macro_lr_model.predict(x_test)\n",
        "optimised_f1_macro_lr_model_f1_test = f1_score(y_test, predictions_f1_macro_model, average='macro')\n",
        "\n",
        "\n",
        "#Time's up\n",
        "print(\"Συνολικός χρόνος train και test: %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz4kgGxqwazR",
        "outputId": "f8867151-d1e2-4813-e2b7-91648729b32d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model optimised on f1-macro score\n",
            "Training Set:\n",
            "LR f1 macro - : 0.838\n",
            "\n",
            "Test set:\n",
            "LR f1 macro:  0.7564935064935064\n",
            "\n",
            "LR Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.52      0.58        21\n",
            "         1.0       0.70      0.79      0.74        29\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.67      0.66      0.66        50\n",
            "weighted avg       0.68      0.68      0.67        50\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Logistic Regression Model optimised on f1-macro score\")\n",
        "\n",
        "#LR_f1_test = f1_score(y_test, LR_predictions, average='macro')\n",
        "\n",
        "# Training set f1-macro score\n",
        "print(\"Training Set:\")\n",
        "#print(\"LR f1 macro: \", np.mean(LR_f1_train)) #?????????\n",
        "print (f'LR f1 macro - : {optimised_f1_macro_lr_model.score(x_train,y_train):.3f}') \n",
        "\n",
        "# Test set f1-macro score and Classification Report \n",
        "print(\"\\nTest set:\")\n",
        "print(\"LR f1 macro: \", optimised_f1_macro_lr_model_f1_test)\n",
        "print('\\nLR Classification Report:\\n' + classification_report(y_test, LR_predictions)+'\\n')\n",
        "\n",
        "# Best parameters\n",
        "#print(lr_opt_f1_macro_train.best_estimator_)\n",
        "#print(lr_opt_f1_macro_train.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkwbnUkwNKus"
      },
      "source": [
        "## Results and conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Classifier | Συνολικός χρόνος train και test (sec) | Out-of-the-Box Accuracy | Optimized Accuracy | Out-of-the-Box f1 score | Optimised f1 score |\n",
        "| --- | :---: | :---: | :---: | :---: | :---: |\n",
        "| Dummy | - | 58 %  | - | 47.2 % | - |\n",
        "| Gnb | 0.07 | 66 % | 68 % | 62.6 % | 66 % |\n",
        "| Knn |  0.056 | 58 % | 92 % | 50.9 % | 91.7 % |\n",
        "| Ls |  144 | 68 %  | 76 % | 66 % | 75 % |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_onIVYFTSdw"
      },
      "source": [
        "### Plots & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "Z9GUu9lGMk35"
      },
      "outputs": [],
      "source": [
        "#Accuracy Scores and F1-macro scores from our experiments\n",
        "\n",
        "# [OOTB accuracy, Optimized accuracy]\n",
        "Dummy_test_acc = [max(test_accuracy.values()), max(test_accuracy.values())]\n",
        "GNB_test_acc = [gnb_accuracy_test, gnb_accuracy_ACC]\n",
        "KNN_test_acc = [kNN_accuracy_test, kNN_acc_acc]\n",
        "LR_test_acc = [LR_accuracy_test, optimised_accuracy_lr_model_accuracy_test] \n",
        "\n",
        "barWidth = 0.25\n",
        "\n",
        "Dummy_test_f1 = [max(test_f1.values()), max(test_f1.values())]\n",
        "GNB_test_f1 = [gnb_f1_test, gnb_f1_F1]\n",
        "KNN_test_f1 = [kNN_f1_test, knn_f1_f1]\n",
        "LR_test_f1 = [LR_f1_test, optimised_f1_macro_lr_model_f1_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "sFYM7W6wXW-I"
      },
      "outputs": [],
      "source": [
        "br1 = np.arange(len(Dummy_test_acc))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "br4 = [x + barWidth for x in br3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIuXFQhcHj_4"
      },
      "source": [
        "**Accuracy Diagram**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "bu-N6SnFLtE6",
        "outputId": "22549ada-7e63-403d-d911-65845fef25b5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Test Set Accuracy Scores Plot\n",
        "\n",
        "barWidth = 0.25\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.bar(br1, Dummy_test_acc, color ='y', width = barWidth,\n",
        "        edgecolor ='grey', label ='Dummy')\n",
        "plt.bar(br2, GNB_test_acc, color ='r', width = barWidth,\n",
        "        edgecolor ='grey', label ='GNB')\n",
        "plt.bar(br3, KNN_test_acc, color ='g', width = barWidth,\n",
        "        edgecolor ='grey', label ='KNN')\n",
        "plt.bar(br4, LR_test_acc, color ='b', width = barWidth,\n",
        "        edgecolor ='grey', label ='LR')\n",
        "\n",
        "plt.xlabel('Branch', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('Accuracy Scores', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + barWidth for r in range(len(GNB_test_acc))],\n",
        "        ['Out of the Box', 'Optimized'])\n",
        " \n",
        "plt.legend()\n",
        "plt.ylim(0.0, 1.0) # Set min, max classifier scores\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wm5aOX3Hf4K"
      },
      "source": [
        "**F1 Diagram**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "QgJK54yXMP9J",
        "outputId": "01c1eb7b-6665-4e29-ddc9-60dfdd2f5777"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Test Set F1-macro Scores Plot\n",
        "\n",
        "barWidth = 0.25\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.bar(br1, Dummy_test_f1, color ='y', width = barWidth,\n",
        "        edgecolor ='grey', label ='Dummy')\n",
        "plt.bar(br2, GNB_test_f1, color ='r', width = barWidth,\n",
        "        edgecolor ='grey', label ='GNB')\n",
        "plt.bar(br3, KNN_test_f1, color ='g', width = barWidth,\n",
        "        edgecolor ='grey', label ='KNN')\n",
        "plt.bar(br4, LR_test_f1, color ='b', width = barWidth,\n",
        "        edgecolor ='grey', label ='LR')\n",
        "\n",
        "plt.xlabel('Branch', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('Test Set F1-macro Scores', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + barWidth for r in range(len(GNB_test_acc))],\n",
        "        ['Out of the Box', 'Optimized'])\n",
        " \n",
        "plt.legend()\n",
        "plt.ylim(0.0, 1.0) # Set min, max classifier scores\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ASTwS6_KQi"
      },
      "source": [
        "###Confusion Matrix\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fHItFknG-_KQ",
        "outputId": "bb3fd977-b836-4365-f0e2-0c46a72d29d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d01ed1cd0>"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion Matrix for the best classifier - K Nearest Neighbors \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns \n",
        "\n",
        "mlp_matrix = confusion_matrix(y_test, kNN_preds_acc)\n",
        "sns.heatmap(mlp_matrix.T, annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "atiGpGY7xSF3",
        "outputId": "d013362f-8aa2-4e02-e2c2-5125506ead02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d01dc9a10>"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion Matrix for classifier - Logistic Regression\n",
        "mlp_matrix = confusion_matrix(y_test, predictions_accuracy_model)\n",
        "sns.heatmap(mlp_matrix.T, annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "AdarVkOCwqFd",
        "outputId": "213e9e90-56c5-4287-ff60-e766b07d1951"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d01a32dd0>"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion Matrix for the worst classifier - Gausian Naive Bayes\n",
        "mlp_matrix = confusion_matrix(y_test, gnb_predictions)\n",
        "sns.heatmap(mlp_matrix.T, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI1sGezq_J0T"
      },
      "source": [
        "Παρατηρούμε ότι στο πίνακα σύγχυσης του βέλτιστου ταξινομητή Knn, τα στοιχεία εμφανίζονται κατά 92% στις θέσεις Τrue Positive ή True Negative. <br>\n",
        "Όμως για τον ταξινομητή Gnb, ο οποίος είναι ο χειρότερος για το dataset αυτό, παρατηρούμε ότι το ποσοστό αυτό στο 68%.  <br><br>\n",
        "\n",
        "Επειδή το σύνολο δεδομένων που εξετάζουμε αφορά το Υποκυτταρικό καρκίνωμα και η ερώτηση που τίθεται να απαντήση ο ταξινομητής είναι ιατρικής φύσης, θέλουμε να αποφύγουμε τα False Positive* στοιχεία καθώς ισχύει :  <br>   \n",
        "\n",
        "Αποτελέσματα :    \n",
        "$\\;\\;\\;\\;\\;\\;$   1 - > Ο ασθενής έζησε - positive <br>\n",
        "$\\;\\;\\;\\;\\;\\;$   0 - > O ασθενής απεβίωσε - negative <br>\n",
        "\n",
        "*(Οι Boolean τιμές είναι ανάποδα από τις σύνηθες ιατρικές τιμές που χρησιμοποιούνται. Όπως για παράδειγμα στο τεστ covid όπου θετικό(1) σημαίνει ότι ο ασθενής έχει τον ιό, ενώ αρνητικό ότι είνα υγιής)\n",
        "\n",
        "Ο βέλτιστος ταξινομητής για το συγκεκριμένο σύνολο δεδομένων και την χρήση του δεν πρέπει να εμφανίζει False Positive καθώς με αυτό τον τρόπο ο ασθενής θα θεωρείτε με λανθασμένη πρόβλεψη πως θα είναι υγιής ενώ στην πραγματικότητα θα αποβιώσει.  \n",
        "\n",
        "Άρα με αυτή την σκοπιά παρατηρούμε ότι ο Knn παραμένει ο καλύτερος ταξινομητής. Στην περίπτωση του χειρότερου ταξινομητή, παρόλο ότι ο Lr ταξινομητής είναι overall καλύτερος από τον Gnb, στην περίπτωση των false positive δεδομένων είναι ο χειρότερος από όλους.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xj_frxyrmo"
      },
      "source": [
        "# Συμπεράσματα\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLP2hq3h04K1"
      },
      "source": [
        "**Συμπεραίνουμε ότι ο καλύτερος ταξινομητής και αυτός ο οποίος προτείνουμε για το συγκεκριμένο σύνολο δεδομένων είναι το K Nearest Neighbors.**\n",
        "\n",
        "Η απόδοση του στο test set είναι πολύ καλύτερη σε όλες τις μετρικές. Ταυτόχρονα εμφανίζει τον μικρότερο αριθμό false positive στοιχείων και αυτό τον καθιστά τον καλύτερο ταξινομητή για την συγκεκριμένη ιατρική εφααρμογή. \n",
        "\n",
        "Η καλή απόδοση του Knn μπορεί να ερμηνευτεί από την μορφή των δεδομένων. Είναι πιθανόν τα δεδομένα να εμφανίζουν μια συγκεκριμένη ομαδοποίηση τέτεια ώστε ο αλγόριθμος να μπορεί να τα διαχωρίσει τα δεδομένα σε σαφής ξεχωριστές ομάδες χωρίς να υπάρχουν πολλά conflicts μεταξύ τους.<br>\n",
        "\n",
        "Για το χειρότερο overall ταξινομητή Gnb, θα μπορούσαμε να πούμε πως τα δεδομένα δεν είναι ανεξάρτητα μεταξύ τους και έτσι δεν μπορεί να δουλέψει σωστά ο Naive Bayes αλγόριθμος. Ιατρικές μετρήσεις και εξετάσεις ενός ανθρώπου δεν γίνεται να είναι ανεξάρτητες μεταξύ τους καθώς όλες γίνονται στο ίδιο οργανισμό. Έτσι, επειδή δεν εξασφαλίζεται η ανεξαρτησία ο αλγόριθμος δεν μπορεί να δουλέψει σωστά.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cONBmEiyWGfn",
        "UEMHhzDHk4jc",
        "sXHrqoI6WYK1",
        "-espkQvNOdWh",
        "-6z8F_n2WllL",
        "rlqHmu3yOdXP"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
